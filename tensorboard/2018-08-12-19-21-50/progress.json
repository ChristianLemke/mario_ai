{"steps": 57, "episode reward": 197.0, "episodes": 2, "mean 100 episode reward": 197.0, "% time spent exploring": 99}
{"steps": 180, "episode reward": 390.0, "episodes": 3, "mean 100 episode reward": 293.5, "% time spent exploring": 99}
{"steps": 214, "episode reward": 224.0, "episodes": 4, "mean 100 episode reward": 270.3, "% time spent exploring": 99}
{"steps": 569, "episode reward": 977.0, "episodes": 5, "mean 100 episode reward": 447.0, "% time spent exploring": 98}
{"steps": 601, "episode reward": 231.0, "episodes": 6, "mean 100 episode reward": 403.8, "% time spent exploring": 98}
{"steps": 2151, "episode reward": 2256.0, "episodes": 7, "mean 100 episode reward": 712.5, "% time spent exploring": 93}
{"steps": 2223, "episode reward": 612.0, "episodes": 8, "mean 100 episode reward": 698.1, "% time spent exploring": 93}
{"steps": 3022, "episode reward": 1713.0, "episodes": 9, "mean 100 episode reward": 825.0, "% time spent exploring": 90}
{"steps": 3161, "episode reward": 605.0, "episodes": 10, "mean 100 episode reward": 800.6, "% time spent exploring": 90}
{"steps": 4232, "episode reward": 1179.0, "episodes": 11, "mean 100 episode reward": 838.4, "% time spent exploring": 87}
{"steps": 4543, "episode reward": 763.0, "episodes": 12, "mean 100 episode reward": 831.5, "% time spent exploring": 86}
{"steps": 4682, "episode reward": 807.0, "episodes": 13, "mean 100 episode reward": 829.5, "% time spent exploring": 85}
{"steps": 4963, "episode reward": 1278.0, "episodes": 14, "mean 100 episode reward": 864.0, "% time spent exploring": 85}
{"steps": 5002, "episode reward": 144.0, "episodes": 15, "mean 100 episode reward": 812.6, "% time spent exploring": 84}
{"steps": 5207, "episode reward": 617.0, "episodes": 16, "mean 100 episode reward": 799.5, "% time spent exploring": 84}
{"steps": 6942, "episode reward": 1504.0, "episodes": 17, "mean 100 episode reward": 843.6, "% time spent exploring": 79}
{"steps": 7104, "episode reward": 625.0, "episodes": 18, "mean 100 episode reward": 830.7, "% time spent exploring": 78}
{"steps": 7796, "episode reward": 1664.0, "episodes": 19, "mean 100 episode reward": 877.0, "% time spent exploring": 76}
{"steps": 8012, "episode reward": 565.0, "episodes": 20, "mean 100 episode reward": 860.6, "% time spent exploring": 75}
{"steps": 8345, "episode reward": 1216.0, "episodes": 21, "mean 100 episode reward": 878.4, "% time spent exploring": 74}
{"steps": 8377, "episode reward": 235.0, "episodes": 22, "mean 100 episode reward": 847.7, "% time spent exploring": 74}
{"steps": 9316, "episode reward": 1454.0, "episodes": 23, "mean 100 episode reward": 875.3, "% time spent exploring": 72}
{"steps": 9557, "episode reward": 705.0, "episodes": 24, "mean 100 episode reward": 867.9, "% time spent exploring": 71}
{"steps": 9860, "episode reward": 1469.0, "episodes": 25, "mean 100 episode reward": 892.9, "% time spent exploring": 70}
{"steps": 9891, "episode reward": 238.0, "episodes": 26, "mean 100 episode reward": 866.7, "% time spent exploring": 70}
{"steps": 10587, "episode reward": 1443.0, "episodes": 27, "mean 100 episode reward": 888.9, "% time spent exploring": 68}
{"steps": 10625, "episode reward": 222.0, "episodes": 28, "mean 100 episode reward": 864.2, "% time spent exploring": 68}
{"steps": 10869, "episode reward": 775.0, "episodes": 29, "mean 100 episode reward": 861.0, "% time spent exploring": 67}
{"steps": 11372, "episode reward": 1776.0, "episodes": 30, "mean 100 episode reward": 892.6, "% time spent exploring": 65}
{"steps": 11411, "episode reward": 135.0, "episodes": 31, "mean 100 episode reward": 867.3, "% time spent exploring": 65}
{"steps": 11501, "episode reward": 598.0, "episodes": 32, "mean 100 episode reward": 858.6, "% time spent exploring": 65}
{"steps": 11801, "episode reward": 979.0, "episodes": 33, "mean 100 episode reward": 862.4, "% time spent exploring": 64}
{"steps": 11844, "episode reward": 219.0, "episodes": 34, "mean 100 episode reward": 842.9, "% time spent exploring": 64}
{"steps": 12624, "episode reward": 2244.0, "episodes": 35, "mean 100 episode reward": 884.1, "% time spent exploring": 62}
{"steps": 12661, "episode reward": 212.0, "episodes": 36, "mean 100 episode reward": 864.9, "% time spent exploring": 62}
{"steps": 13024, "episode reward": 1218.0, "episodes": 37, "mean 100 episode reward": 874.7, "% time spent exploring": 60}
{"steps": 13171, "episode reward": 628.0, "episodes": 38, "mean 100 episode reward": 868.0, "% time spent exploring": 60}
{"steps": 13472, "episode reward": 1383.0, "episodes": 39, "mean 100 episode reward": 881.6, "% time spent exploring": 59}
{"steps": 14138, "episode reward": 530.0, "episodes": 40, "mean 100 episode reward": 872.6, "% time spent exploring": 57}
{"steps": 14630, "episode reward": 1484.0, "episodes": 41, "mean 100 episode reward": 887.8, "% time spent exploring": 56}
{"steps": 14666, "episode reward": 236.0, "episodes": 42, "mean 100 episode reward": 872.0, "% time spent exploring": 56}
{"steps": 15020, "episode reward": 1316.0, "episodes": 43, "mean 100 episode reward": 882.5, "% time spent exploring": 54}
{"steps": 15439, "episode reward": 1258.0, "episodes": 44, "mean 100 episode reward": 891.3, "% time spent exploring": 53}
{"steps": 15537, "episode reward": 588.0, "episodes": 45, "mean 100 episode reward": 884.4, "% time spent exploring": 53}
{"steps": 15908, "episode reward": 1080.0, "episodes": 46, "mean 100 episode reward": 888.7, "% time spent exploring": 52}
{"steps": 16141, "episode reward": 1236.0, "episodes": 47, "mean 100 episode reward": 896.3, "% time spent exploring": 51}
{"steps": 16203, "episode reward": 591.0, "episodes": 48, "mean 100 episode reward": 889.8, "% time spent exploring": 51}
{"steps": 16412, "episode reward": 966.0, "episodes": 49, "mean 100 episode reward": 891.4, "% time spent exploring": 50}
{"steps": 16541, "episode reward": 616.0, "episodes": 50, "mean 100 episode reward": 885.7, "% time spent exploring": 50}
{"steps": 17039, "episode reward": 1517.0, "episodes": 51, "mean 100 episode reward": 898.4, "% time spent exploring": 48}
{"steps": 17341, "episode reward": 1302.0, "episodes": 52, "mean 100 episode reward": 906.3, "% time spent exploring": 47}
{"steps": 17382, "episode reward": 140.0, "episodes": 53, "mean 100 episode reward": 891.5, "% time spent exploring": 47}
{"steps": 17491, "episode reward": 595.0, "episodes": 54, "mean 100 episode reward": 885.9, "% time spent exploring": 47}
{"steps": 18138, "episode reward": 2056.0, "episodes": 55, "mean 100 episode reward": 907.6, "% time spent exploring": 45}
{"steps": 18416, "episode reward": 1098.0, "episodes": 56, "mean 100 episode reward": 911.1, "% time spent exploring": 44}
{"steps": 18495, "episode reward": 439.0, "episodes": 57, "mean 100 episode reward": 902.6, "% time spent exploring": 44}
{"steps": 18737, "episode reward": 732.0, "episodes": 58, "mean 100 episode reward": 899.6, "% time spent exploring": 43}
{"steps": 19072, "episode reward": 1236.0, "episodes": 59, "mean 100 episode reward": 905.4, "% time spent exploring": 42}
{"steps": 19154, "episode reward": 595.0, "episodes": 60, "mean 100 episode reward": 900.2, "% time spent exploring": 42}
{"steps": 19581, "episode reward": 1198.0, "episodes": 61, "mean 100 episode reward": 905.2, "% time spent exploring": 41}
{"steps": 19621, "episode reward": 232.0, "episodes": 62, "mean 100 episode reward": 894.1, "% time spent exploring": 41}
{"steps": 21164, "episode reward": 2115.0, "episodes": 63, "mean 100 episode reward": 913.8, "% time spent exploring": 36}
{"steps": 21206, "episode reward": 208.0, "episodes": 64, "mean 100 episode reward": 902.6, "% time spent exploring": 36}
{"steps": 21423, "episode reward": 1552.0, "episodes": 65, "mean 100 episode reward": 912.8, "% time spent exploring": 35}
{"steps": 21603, "episode reward": 690.0, "episodes": 66, "mean 100 episode reward": 909.3, "% time spent exploring": 35}
{"steps": 22089, "episode reward": 2240.0, "episodes": 67, "mean 100 episode reward": 929.5, "% time spent exploring": 33}
{"steps": 22392, "episode reward": 1658.0, "episodes": 68, "mean 100 episode reward": 940.4, "% time spent exploring": 32}
{"steps": 22478, "episode reward": 456.0, "episodes": 69, "mean 100 episode reward": 933.2, "% time spent exploring": 32}
{"steps": 22682, "episode reward": 693.0, "episodes": 70, "mean 100 episode reward": 929.8, "% time spent exploring": 31}
{"steps": 22975, "episode reward": 1502.0, "episodes": 71, "mean 100 episode reward": 937.9, "% time spent exploring": 31}
{"steps": 23188, "episode reward": 531.0, "episodes": 72, "mean 100 episode reward": 932.2, "% time spent exploring": 30}
{"steps": 25179, "episode reward": 1049.0, "episodes": 73, "mean 100 episode reward": 933.8, "% time spent exploring": 24}
{"steps": 25339, "episode reward": 802.0, "episodes": 74, "mean 100 episode reward": 932.0, "% time spent exploring": 23}
{"steps": 25561, "episode reward": 1192.0, "episodes": 75, "mean 100 episode reward": 935.5, "% time spent exploring": 23}
{"steps": 25669, "episode reward": 603.0, "episodes": 76, "mean 100 episode reward": 931.1, "% time spent exploring": 22}
{"steps": 25891, "episode reward": 1260.0, "episodes": 77, "mean 100 episode reward": 935.4, "% time spent exploring": 22}
{"steps": 26200, "episode reward": 772.0, "episodes": 78, "mean 100 episode reward": 933.3, "% time spent exploring": 21}
{"steps": 26409, "episode reward": 1252.0, "episodes": 79, "mean 100 episode reward": 937.4, "% time spent exploring": 20}
{"steps": 26444, "episode reward": 232.0, "episodes": 80, "mean 100 episode reward": 928.5, "% time spent exploring": 20}
{"steps": 26790, "episode reward": 906.0, "episodes": 81, "mean 100 episode reward": 928.2, "% time spent exploring": 19}
{"steps": 27040, "episode reward": 1404.0, "episodes": 82, "mean 100 episode reward": 934.0, "% time spent exploring": 18}
{"steps": 27077, "episode reward": 113.0, "episodes": 83, "mean 100 episode reward": 924.0, "% time spent exploring": 18}
{"steps": 27495, "episode reward": 692.0, "episodes": 84, "mean 100 episode reward": 921.2, "% time spent exploring": 17}
{"steps": 27667, "episode reward": 661.0, "episodes": 85, "mean 100 episode reward": 918.1, "% time spent exploring": 16}
{"steps": 27809, "episode reward": 629.0, "episodes": 86, "mean 100 episode reward": 914.7, "% time spent exploring": 16}
{"steps": 28029, "episode reward": 1402.0, "episodes": 87, "mean 100 episode reward": 920.4, "% time spent exploring": 15}
{"steps": 28064, "episode reward": 235.0, "episodes": 88, "mean 100 episode reward": 912.5, "% time spent exploring": 15}
{"steps": 28541, "episode reward": 1619.0, "episodes": 89, "mean 100 episode reward": 920.6, "% time spent exploring": 14}
{"steps": 28646, "episode reward": 604.0, "episodes": 90, "mean 100 episode reward": 917.0, "% time spent exploring": 14}
{"steps": 29094, "episode reward": 1624.0, "episodes": 91, "mean 100 episode reward": 924.9, "% time spent exploring": 12}
{"steps": 29168, "episode reward": 598.0, "episodes": 92, "mean 100 episode reward": 921.3, "% time spent exploring": 12}
{"steps": 29317, "episode reward": 1198.0, "episodes": 93, "mean 100 episode reward": 924.3, "% time spent exploring": 12}
{"steps": 29480, "episode reward": 1130.0, "episodes": 94, "mean 100 episode reward": 926.5, "% time spent exploring": 11}
{"steps": 30677, "episode reward": 1288.0, "episodes": 95, "mean 100 episode reward": 930.3, "% time spent exploring": 9}
{"steps": 30745, "episode reward": 610.0, "episodes": 96, "mean 100 episode reward": 927.0, "% time spent exploring": 9}
{"steps": 31082, "episode reward": 1366.0, "episodes": 97, "mean 100 episode reward": 931.5, "% time spent exploring": 9}
{"steps": 31249, "episode reward": 1027.0, "episodes": 98, "mean 100 episode reward": 932.5, "% time spent exploring": 9}
{"steps": 31535, "episode reward": 1239.0, "episodes": 99, "mean 100 episode reward": 935.6, "% time spent exploring": 9}
{"steps": 31572, "episode reward": 216.0, "episodes": 100, "mean 100 episode reward": 928.4, "% time spent exploring": 9}
{"steps": 31818, "episode reward": 1236.0, "episodes": 101, "mean 100 episode reward": 931.4, "% time spent exploring": 9}
{"steps": 32603, "episode reward": 3569.0, "episodes": 102, "mean 100 episode reward": 965.2, "% time spent exploring": 9}
{"steps": 32697, "episode reward": 698.0, "episodes": 103, "mean 100 episode reward": 968.2, "% time spent exploring": 9}
{"steps": 32893, "episode reward": 1019.0, "episodes": 104, "mean 100 episode reward": 976.2, "% time spent exploring": 9}
{"steps": 33008, "episode reward": 815.0, "episodes": 105, "mean 100 episode reward": 974.6, "% time spent exploring": 9}
{"steps": 33153, "episode reward": 1033.0, "episodes": 106, "mean 100 episode reward": 982.6, "% time spent exploring": 9}
{"steps": 33493, "episode reward": 1915.0, "episodes": 107, "mean 100 episode reward": 979.2, "% time spent exploring": 9}
{"steps": 33788, "episode reward": 1002.0, "episodes": 108, "mean 100 episode reward": 983.1, "% time spent exploring": 9}
{"steps": 33926, "episode reward": 807.0, "episodes": 109, "mean 100 episode reward": 974.0, "% time spent exploring": 9}
{"steps": 35208, "episode reward": 1107.0, "episodes": 110, "mean 100 episode reward": 979.0, "% time spent exploring": 9}
{"steps": 35273, "episode reward": 471.0, "episodes": 111, "mean 100 episode reward": 972.0, "% time spent exploring": 9}
{"steps": 35429, "episode reward": 802.0, "episodes": 112, "mean 100 episode reward": 972.4, "% time spent exploring": 9}
{"steps": 35836, "episode reward": 2127.0, "episodes": 113, "mean 100 episode reward": 985.6, "% time spent exploring": 9}
{"steps": 36064, "episode reward": 1409.0, "episodes": 114, "mean 100 episode reward": 986.9, "% time spent exploring": 9}
{"steps": 36096, "episode reward": 161.0, "episodes": 115, "mean 100 episode reward": 987.0, "% time spent exploring": 9}
{"steps": 36180, "episode reward": 599.0, "episodes": 116, "mean 100 episode reward": 986.9, "% time spent exploring": 9}
{"steps": 36361, "episode reward": 1253.0, "episodes": 117, "mean 100 episode reward": 984.4, "% time spent exploring": 9}
{"steps": 36471, "episode reward": 601.0, "episodes": 118, "mean 100 episode reward": 984.1, "% time spent exploring": 9}
{"steps": 36796, "episode reward": 1740.0, "episodes": 119, "mean 100 episode reward": 984.9, "% time spent exploring": 9}
{"steps": 36930, "episode reward": 631.0, "episodes": 120, "mean 100 episode reward": 985.5, "% time spent exploring": 9}
{"steps": 37268, "episode reward": 1166.0, "episodes": 121, "mean 100 episode reward": 985.0, "% time spent exploring": 9}
{"steps": 37524, "episode reward": 1026.0, "episodes": 122, "mean 100 episode reward": 992.9, "% time spent exploring": 9}
{"steps": 37638, "episode reward": 825.0, "episodes": 123, "mean 100 episode reward": 986.6, "% time spent exploring": 9}
{"steps": 37829, "episode reward": 795.0, "episodes": 124, "mean 100 episode reward": 987.6, "% time spent exploring": 9}
{"steps": 38483, "episode reward": 1293.0, "episodes": 125, "mean 100 episode reward": 985.8, "% time spent exploring": 9}
{"steps": 38624, "episode reward": 629.0, "episodes": 126, "mean 100 episode reward": 989.7, "% time spent exploring": 9}
{"steps": 38878, "episode reward": 1243.0, "episodes": 127, "mean 100 episode reward": 987.7, "% time spent exploring": 9}
{"steps": 39132, "episode reward": 1405.0, "episodes": 128, "mean 100 episode reward": 999.5, "% time spent exploring": 9}
{"steps": 39297, "episode reward": 1172.0, "episodes": 129, "mean 100 episode reward": 1003.5, "% time spent exploring": 9}
{"steps": 39928, "episode reward": 1320.0, "episodes": 130, "mean 100 episode reward": 998.9, "% time spent exploring": 9}
{"steps": 39961, "episode reward": 139.0, "episodes": 131, "mean 100 episode reward": 999.0, "% time spent exploring": 9}
{"steps": 40246, "episode reward": 1006.0, "episodes": 132, "mean 100 episode reward": 1003.1, "% time spent exploring": 9}
{"steps": 40441, "episode reward": 1492.0, "episodes": 133, "mean 100 episode reward": 1008.2, "% time spent exploring": 9}
{"steps": 40576, "episode reward": 631.0, "episodes": 134, "mean 100 episode reward": 1012.3, "% time spent exploring": 9}
{"steps": 41205, "episode reward": 2002.0, "episodes": 135, "mean 100 episode reward": 1009.9, "% time spent exploring": 9}
{"steps": 41367, "episode reward": 1322.0, "episodes": 136, "mean 100 episode reward": 1021.0, "% time spent exploring": 9}
{"steps": 41398, "episode reward": 146.0, "episodes": 137, "mean 100 episode reward": 1010.3, "% time spent exploring": 9}
{"steps": 41425, "episode reward": 237.0, "episodes": 138, "mean 100 episode reward": 1006.4, "% time spent exploring": 9}
{"steps": 41620, "episode reward": 1395.0, "episodes": 139, "mean 100 episode reward": 1006.5, "% time spent exploring": 9}
{"steps": 41890, "episode reward": 1836.0, "episodes": 140, "mean 100 episode reward": 1019.5, "% time spent exploring": 9}
{"steps": 42399, "episode reward": 1101.0, "episodes": 141, "mean 100 episode reward": 1015.7, "% time spent exploring": 9}
{"steps": 42427, "episode reward": 237.0, "episodes": 142, "mean 100 episode reward": 1015.7, "% time spent exploring": 9}
{"steps": 42651, "episode reward": 1398.0, "episodes": 143, "mean 100 episode reward": 1016.5, "% time spent exploring": 9}
{"steps": 42810, "episode reward": 746.0, "episodes": 144, "mean 100 episode reward": 1011.4, "% time spent exploring": 9}
{"steps": 42916, "episode reward": 838.0, "episodes": 145, "mean 100 episode reward": 1013.9, "% time spent exploring": 9}
{"steps": 42943, "episode reward": 233.0, "episodes": 146, "mean 100 episode reward": 1005.4, "% time spent exploring": 9}
{"steps": 43164, "episode reward": 1642.0, "episodes": 147, "mean 100 episode reward": 1009.5, "% time spent exploring": 9}
{"steps": 43191, "episode reward": 237.0, "episodes": 148, "mean 100 episode reward": 1006.0, "% time spent exploring": 9}
{"steps": 43445, "episode reward": 1898.0, "episodes": 149, "mean 100 episode reward": 1015.3, "% time spent exploring": 9}
{"steps": 43472, "episode reward": 237.0, "episodes": 150, "mean 100 episode reward": 1011.5, "% time spent exploring": 9}
{"steps": 43873, "episode reward": 1995.0, "episodes": 151, "mean 100 episode reward": 1016.3, "% time spent exploring": 9}
{"steps": 44236, "episode reward": 1382.0, "episodes": 152, "mean 100 episode reward": 1017.1, "% time spent exploring": 9}
{"steps": 44267, "episode reward": 166.0, "episodes": 153, "mean 100 episode reward": 1017.3, "% time spent exploring": 9}
{"steps": 44411, "episode reward": 758.0, "episodes": 154, "mean 100 episode reward": 1019.0, "% time spent exploring": 9}
{"steps": 44581, "episode reward": 970.0, "episodes": 155, "mean 100 episode reward": 1008.1, "% time spent exploring": 9}
{"steps": 44739, "episode reward": 1030.0, "episodes": 156, "mean 100 episode reward": 1007.4, "% time spent exploring": 9}
{"steps": 45019, "episode reward": 1911.0, "episodes": 157, "mean 100 episode reward": 1022.2, "% time spent exploring": 9}
{"steps": 45046, "episode reward": 239.0, "episodes": 158, "mean 100 episode reward": 1017.2, "% time spent exploring": 9}
{"steps": 45193, "episode reward": 1206.0, "episodes": 159, "mean 100 episode reward": 1016.9, "% time spent exploring": 9}
{"steps": 45492, "episode reward": 1294.0, "episodes": 160, "mean 100 episode reward": 1023.9, "% time spent exploring": 9}
{"steps": 45522, "episode reward": 165.0, "episodes": 161, "mean 100 episode reward": 1013.6, "% time spent exploring": 9}
{"steps": 45816, "episode reward": 1387.0, "episodes": 162, "mean 100 episode reward": 1025.1, "% time spent exploring": 9}
{"steps": 45849, "episode reward": 169.0, "episodes": 163, "mean 100 episode reward": 1005.7, "% time spent exploring": 9}
{"steps": 46395, "episode reward": 690.0, "episodes": 164, "mean 100 episode reward": 1010.5, "% time spent exploring": 9}
{"steps": 46540, "episode reward": 1222.0, "episodes": 165, "mean 100 episode reward": 1007.2, "% time spent exploring": 9}
{"steps": 46569, "episode reward": 231.0, "episodes": 166, "mean 100 episode reward": 1002.6, "% time spent exploring": 9}
{"steps": 46626, "episode reward": 456.0, "episodes": 167, "mean 100 episode reward": 984.8, "% time spent exploring": 9}
{"steps": 46684, "episode reward": 598.0, "episodes": 168, "mean 100 episode reward": 974.2, "% time spent exploring": 9}
{"steps": 46913, "episode reward": 792.0, "episodes": 169, "mean 100 episode reward": 977.5, "% time spent exploring": 9}
{"steps": 47046, "episode reward": 1037.0, "episodes": 170, "mean 100 episode reward": 981.0, "% time spent exploring": 9}
{"steps": 47319, "episode reward": 2035.0, "episodes": 171, "mean 100 episode reward": 986.3, "% time spent exploring": 9}
{"steps": 47346, "episode reward": 229.0, "episodes": 172, "mean 100 episode reward": 983.3, "% time spent exploring": 9}
{"steps": 47607, "episode reward": 2238.0, "episodes": 173, "mean 100 episode reward": 995.2, "% time spent exploring": 9}
{"steps": 47745, "episode reward": 1032.0, "episodes": 174, "mean 100 episode reward": 997.5, "% time spent exploring": 9}
{"steps": 48071, "episode reward": 1614.0, "episodes": 175, "mean 100 episode reward": 1001.7, "% time spent exploring": 9}
{"steps": 48106, "episode reward": 217.0, "episodes": 176, "mean 100 episode reward": 997.8, "% time spent exploring": 9}
{"steps": 48518, "episode reward": 1306.0, "episodes": 177, "mean 100 episode reward": 998.3, "% time spent exploring": 9}
{"steps": 48678, "episode reward": 802.0, "episodes": 178, "mean 100 episode reward": 998.6, "% time spent exploring": 9}
{"steps": 49368, "episode reward": 1977.0, "episodes": 179, "mean 100 episode reward": 1005.8, "% time spent exploring": 9}
{"steps": 49442, "episode reward": 625.0, "episodes": 180, "mean 100 episode reward": 1009.8, "% time spent exploring": 9}
{"steps": 49680, "episode reward": 1916.0, "episodes": 181, "mean 100 episode reward": 1019.9, "% time spent exploring": 9}
{"steps": 49759, "episode reward": 605.0, "episodes": 182, "mean 100 episode reward": 1011.9, "% time spent exploring": 9}
{"steps": 50197, "episode reward": 1198.0, "episodes": 183, "mean 100 episode reward": 1022.7, "% time spent exploring": 9}
{"steps": 50276, "episode reward": 599.0, "episodes": 184, "mean 100 episode reward": 1021.8, "% time spent exploring": 9}
{"steps": 50450, "episode reward": 1227.0, "episodes": 185, "mean 100 episode reward": 1027.4, "% time spent exploring": 9}
{"steps": 50480, "episode reward": 236.0, "episodes": 186, "mean 100 episode reward": 1023.5, "% time spent exploring": 9}
{"steps": 50914, "episode reward": 1519.0, "episodes": 187, "mean 100 episode reward": 1024.7, "% time spent exploring": 9}
{"steps": 51062, "episode reward": 1325.0, "episodes": 188, "mean 100 episode reward": 1035.6, "% time spent exploring": 9}
{"steps": 51099, "episode reward": 238.0, "episodes": 189, "mean 100 episode reward": 1021.8, "% time spent exploring": 9}
{"steps": 51158, "episode reward": 599.0, "episodes": 190, "mean 100 episode reward": 1021.7, "% time spent exploring": 9}
{"steps": 52086, "episode reward": 1264.0, "episodes": 191, "mean 100 episode reward": 1018.1, "% time spent exploring": 9}
{"steps": 52161, "episode reward": 590.0, "episodes": 192, "mean 100 episode reward": 1018.0, "% time spent exploring": 9}
{"steps": 52314, "episode reward": 1203.0, "episodes": 193, "mean 100 episode reward": 1018.1, "% time spent exploring": 9}
{"steps": 52479, "episode reward": 801.0, "episodes": 194, "mean 100 episode reward": 1014.8, "% time spent exploring": 9}
{"steps": 52780, "episode reward": 1334.0, "episodes": 195, "mean 100 episode reward": 1015.3, "% time spent exploring": 9}
{"steps": 52946, "episode reward": 1417.0, "episodes": 196, "mean 100 episode reward": 1023.3, "% time spent exploring": 9}
{"steps": 52977, "episode reward": 164.0, "episodes": 197, "mean 100 episode reward": 1011.3, "% time spent exploring": 9}
{"steps": 53010, "episode reward": 222.0, "episodes": 198, "mean 100 episode reward": 1003.3, "% time spent exploring": 9}
{"steps": 53231, "episode reward": 1910.0, "episodes": 199, "mean 100 episode reward": 1010.0, "% time spent exploring": 9}
{"steps": 53438, "episode reward": 710.0, "episodes": 200, "mean 100 episode reward": 1014.9, "% time spent exploring": 9}
{"steps": 53693, "episode reward": 2154.0, "episodes": 201, "mean 100 episode reward": 1024.1, "% time spent exploring": 9}
{"steps": 53876, "episode reward": 736.0, "episodes": 202, "mean 100 episode reward": 995.8, "% time spent exploring": 9}
{"steps": 54196, "episode reward": 1911.0, "episodes": 203, "mean 100 episode reward": 1007.9, "% time spent exploring": 9}
{"steps": 54323, "episode reward": 757.0, "episodes": 204, "mean 100 episode reward": 1005.3, "% time spent exploring": 9}
{"steps": 54596, "episode reward": 2075.0, "episodes": 205, "mean 100 episode reward": 1017.9, "% time spent exploring": 9}
{"steps": 54678, "episode reward": 624.0, "episodes": 206, "mean 100 episode reward": 1013.8, "% time spent exploring": 9}
{"steps": 54855, "episode reward": 1024.0, "episodes": 207, "mean 100 episode reward": 1004.9, "% time spent exploring": 9}
{"steps": 55010, "episode reward": 1033.0, "episodes": 208, "mean 100 episode reward": 1005.2, "% time spent exploring": 9}
{"steps": 55195, "episode reward": 1411.0, "episodes": 209, "mean 100 episode reward": 1011.2, "% time spent exploring": 9}
{"steps": 55224, "episode reward": 226.0, "episodes": 210, "mean 100 episode reward": 1002.4, "% time spent exploring": 9}
{"steps": 55437, "episode reward": 1651.0, "episodes": 211, "mean 100 episode reward": 1014.2, "% time spent exploring": 9}
{"steps": 55464, "episode reward": 239.0, "episodes": 212, "mean 100 episode reward": 1008.6, "% time spent exploring": 9}
{"steps": 55593, "episode reward": 797.0, "episodes": 213, "mean 100 episode reward": 995.3, "% time spent exploring": 9}
{"steps": 55780, "episode reward": 1129.0, "episodes": 214, "mean 100 episode reward": 992.5, "% time spent exploring": 9}
{"steps": 55977, "episode reward": 1253.0, "episodes": 215, "mean 100 episode reward": 1003.4, "% time spent exploring": 9}
{"steps": 57151, "episode reward": 1215.0, "episodes": 216, "mean 100 episode reward": 1009.6, "% time spent exploring": 9}
{"steps": 57187, "episode reward": 138.0, "episodes": 217, "mean 100 episode reward": 998.4, "% time spent exploring": 9}
{"steps": 57390, "episode reward": 718.0, "episodes": 218, "mean 100 episode reward": 999.6, "% time spent exploring": 9}
{"steps": 57639, "episode reward": 1388.0, "episodes": 219, "mean 100 episode reward": 996.1, "% time spent exploring": 9}
{"steps": 57891, "episode reward": 1306.0, "episodes": 220, "mean 100 episode reward": 1002.8, "% time spent exploring": 9}
{"steps": 57930, "episode reward": 216.0, "episodes": 221, "mean 100 episode reward": 993.3, "% time spent exploring": 9}
{"steps": 57958, "episode reward": 233.0, "episodes": 222, "mean 100 episode reward": 985.4, "% time spent exploring": 9}
{"steps": 58269, "episode reward": 1387.0, "episodes": 223, "mean 100 episode reward": 991.0, "% time spent exploring": 9}
{"steps": 58410, "episode reward": 629.0, "episodes": 224, "mean 100 episode reward": 989.4, "% time spent exploring": 9}
{"steps": 58698, "episode reward": 2173.0, "episodes": 225, "mean 100 episode reward": 998.2, "% time spent exploring": 9}
{"steps": 58778, "episode reward": 619.0, "episodes": 226, "mean 100 episode reward": 998.0, "% time spent exploring": 9}
{"steps": 59011, "episode reward": 1643.0, "episodes": 227, "mean 100 episode reward": 1002.0, "% time spent exploring": 9}
{"steps": 59160, "episode reward": 757.0, "episodes": 228, "mean 100 episode reward": 995.6, "% time spent exploring": 9}
{"steps": 59282, "episode reward": 805.0, "episodes": 229, "mean 100 episode reward": 991.9, "% time spent exploring": 9}
{"steps": 59497, "episode reward": 1305.0, "episodes": 230, "mean 100 episode reward": 991.8, "% time spent exploring": 9}
{"steps": 59529, "episode reward": 167.0, "episodes": 231, "mean 100 episode reward": 992.0, "% time spent exploring": 9}
{"steps": 59781, "episode reward": 1009.0, "episodes": 232, "mean 100 episode reward": 992.1, "% time spent exploring": 9}
{"steps": 59951, "episode reward": 1214.0, "episodes": 233, "mean 100 episode reward": 989.3, "% time spent exploring": 9}
{"steps": 60022, "episode reward": 600.0, "episodes": 234, "mean 100 episode reward": 989.0, "% time spent exploring": 9}
{"steps": 60190, "episode reward": 1555.0, "episodes": 235, "mean 100 episode reward": 984.5, "% time spent exploring": 9}
{"steps": 60846, "episode reward": 2272.0, "episodes": 236, "mean 100 episode reward": 994.0, "% time spent exploring": 9}
{"steps": 60878, "episode reward": 162.0, "episodes": 237, "mean 100 episode reward": 994.2, "% time spent exploring": 9}
{"steps": 60911, "episode reward": 223.0, "episodes": 238, "mean 100 episode reward": 994.0, "% time spent exploring": 9}
{"steps": 61145, "episode reward": 1632.0, "episodes": 239, "mean 100 episode reward": 996.4, "% time spent exploring": 9}
{"steps": 61351, "episode reward": 792.0, "episodes": 240, "mean 100 episode reward": 986.0, "% time spent exploring": 9}
{"steps": 61445, "episode reward": 838.0, "episodes": 241, "mean 100 episode reward": 983.3, "% time spent exploring": 9}
{"steps": 61704, "episode reward": 1012.0, "episodes": 242, "mean 100 episode reward": 991.1, "% time spent exploring": 9}
{"steps": 61893, "episode reward": 1402.0, "episodes": 243, "mean 100 episode reward": 991.1, "% time spent exploring": 9}
{"steps": 62048, "episode reward": 735.0, "episodes": 244, "mean 100 episode reward": 991.0, "% time spent exploring": 9}
{"steps": 62170, "episode reward": 819.0, "episodes": 245, "mean 100 episode reward": 990.8, "% time spent exploring": 9}
{"steps": 62242, "episode reward": 627.0, "episodes": 246, "mean 100 episode reward": 994.8, "% time spent exploring": 9}
{"steps": 62567, "episode reward": 1462.0, "episodes": 247, "mean 100 episode reward": 993.0, "% time spent exploring": 9}
{"steps": 62637, "episode reward": 589.0, "episodes": 248, "mean 100 episode reward": 996.5, "% time spent exploring": 9}
{"steps": 63083, "episode reward": 1611.0, "episodes": 249, "mean 100 episode reward": 993.6, "% time spent exploring": 9}
{"steps": 63176, "episode reward": 584.0, "episodes": 250, "mean 100 episode reward": 997.1, "% time spent exploring": 9}
{"steps": 63282, "episode reward": 819.0, "episodes": 251, "mean 100 episode reward": 985.3, "% time spent exploring": 9}
{"steps": 63359, "episode reward": 618.0, "episodes": 252, "mean 100 episode reward": 977.7, "% time spent exploring": 9}
{"steps": 63559, "episode reward": 1574.0, "episodes": 253, "mean 100 episode reward": 991.8, "% time spent exploring": 9}
{"steps": 63589, "episode reward": 223.0, "episodes": 254, "mean 100 episode reward": 986.4, "% time spent exploring": 9}
{"steps": 63885, "episode reward": 1603.0, "episodes": 255, "mean 100 episode reward": 992.7, "% time spent exploring": 9}
{"steps": 63943, "episode reward": 592.0, "episodes": 256, "mean 100 episode reward": 988.4, "% time spent exploring": 9}
{"steps": 64218, "episode reward": 1532.0, "episodes": 257, "mean 100 episode reward": 984.6, "% time spent exploring": 9}
{"steps": 64309, "episode reward": 612.0, "episodes": 258, "mean 100 episode reward": 988.3, "% time spent exploring": 9}
{"steps": 64564, "episode reward": 1731.0, "episodes": 259, "mean 100 episode reward": 993.5, "% time spent exploring": 9}
{"steps": 64771, "episode reward": 1407.0, "episodes": 260, "mean 100 episode reward": 994.7, "% time spent exploring": 9}
{"steps": 64804, "episode reward": 165.0, "episodes": 261, "mean 100 episode reward": 994.7, "% time spent exploring": 9}
{"steps": 64873, "episode reward": 618.0, "episodes": 262, "mean 100 episode reward": 987.0, "% time spent exploring": 9}
{"steps": 65430, "episode reward": 1602.0, "episodes": 263, "mean 100 episode reward": 1001.3, "% time spent exploring": 9}
{"steps": 65503, "episode reward": 604.0, "episodes": 264, "mean 100 episode reward": 1000.4, "% time spent exploring": 9}
{"steps": 65847, "episode reward": 1619.0, "episodes": 265, "mean 100 episode reward": 1004.4, "% time spent exploring": 9}
{"steps": 66040, "episode reward": 1326.0, "episodes": 266, "mean 100 episode reward": 1015.4, "% time spent exploring": 9}
{"steps": 66145, "episode reward": 144.0, "episodes": 267, "mean 100 episode reward": 1012.2, "% time spent exploring": 9}
{"steps": 66211, "episode reward": 609.0, "episodes": 268, "mean 100 episode reward": 1012.4, "% time spent exploring": 9}
{"steps": 66433, "episode reward": 1363.0, "episodes": 269, "mean 100 episode reward": 1018.1, "% time spent exploring": 9}
{"steps": 66496, "episode reward": 603.0, "episodes": 270, "mean 100 episode reward": 1013.7, "% time spent exploring": 9}
{"steps": 66618, "episode reward": 815.0, "episodes": 271, "mean 100 episode reward": 1001.5, "% time spent exploring": 9}
{"steps": 66761, "episode reward": 805.0, "episodes": 272, "mean 100 episode reward": 1007.3, "% time spent exploring": 9}
{"steps": 66858, "episode reward": 835.0, "episodes": 273, "mean 100 episode reward": 993.3, "% time spent exploring": 9}
{"steps": 67021, "episode reward": 1132.0, "episodes": 274, "mean 100 episode reward": 994.3, "% time spent exploring": 9}
{"steps": 67077, "episode reward": 464.0, "episodes": 275, "mean 100 episode reward": 982.8, "% time spent exploring": 9}
{"steps": 67104, "episode reward": 238.0, "episodes": 276, "mean 100 episode reward": 983.0, "% time spent exploring": 9}
{"steps": 67260, "episode reward": 1033.0, "episodes": 277, "mean 100 episode reward": 980.2, "% time spent exploring": 9}
{"steps": 67425, "episode reward": 1030.0, "episodes": 278, "mean 100 episode reward": 982.5, "% time spent exploring": 9}
{"steps": 67687, "episode reward": 1612.0, "episodes": 279, "mean 100 episode reward": 978.9, "% time spent exploring": 9}
{"steps": 68187, "episode reward": 961.0, "episodes": 280, "mean 100 episode reward": 982.2, "% time spent exploring": 9}
{"steps": 68492, "episode reward": 1964.0, "episodes": 281, "mean 100 episode reward": 982.7, "% time spent exploring": 9}
{"steps": 68575, "episode reward": 588.0, "episodes": 282, "mean 100 episode reward": 982.5, "% time spent exploring": 9}
{"steps": 68665, "episode reward": 825.0, "episodes": 283, "mean 100 episode reward": 978.8, "% time spent exploring": 9}
{"steps": 68722, "episode reward": 589.0, "episodes": 284, "mean 100 episode reward": 978.7, "% time spent exploring": 9}
{"steps": 68817, "episode reward": 842.0, "episodes": 285, "mean 100 episode reward": 974.9, "% time spent exploring": 9}
{"steps": 68981, "episode reward": 801.0, "episodes": 286, "mean 100 episode reward": 980.5, "% time spent exploring": 9}
{"steps": 69336, "episode reward": 1820.0, "episodes": 287, "mean 100 episode reward": 983.5, "% time spent exploring": 9}
{"steps": 69370, "episode reward": 225.0, "episodes": 288, "mean 100 episode reward": 972.5, "% time spent exploring": 9}
{"steps": 69695, "episode reward": 1539.0, "episodes": 289, "mean 100 episode reward": 985.5, "% time spent exploring": 9}
{"steps": 69733, "episode reward": 213.0, "episodes": 290, "mean 100 episode reward": 981.7, "% time spent exploring": 9}
{"steps": 70076, "episode reward": 1226.0, "episodes": 291, "mean 100 episode reward": 981.3, "% time spent exploring": 9}
{"steps": 70133, "episode reward": 592.0, "episodes": 292, "mean 100 episode reward": 981.3, "% time spent exploring": 9}
{"steps": 70235, "episode reward": 873.0, "episodes": 293, "mean 100 episode reward": 978.0, "% time spent exploring": 9}
{"steps": 70305, "episode reward": 601.0, "episodes": 294, "mean 100 episode reward": 976.0, "% time spent exploring": 9}
{"steps": 70400, "episode reward": 813.0, "episodes": 295, "mean 100 episode reward": 970.8, "% time spent exploring": 9}
{"steps": 70591, "episode reward": 1326.0, "episodes": 296, "mean 100 episode reward": 969.9, "% time spent exploring": 9}
{"steps": 70623, "episode reward": 126.0, "episodes": 297, "mean 100 episode reward": 969.5, "% time spent exploring": 9}
{"steps": 70650, "episode reward": 238.0, "episodes": 298, "mean 100 episode reward": 969.7, "% time spent exploring": 9}
{"steps": 71220, "episode reward": 1321.0, "episodes": 299, "mean 100 episode reward": 963.8, "% time spent exploring": 9}
{"steps": 71247, "episode reward": 239.0, "episodes": 300, "mean 100 episode reward": 959.1, "% time spent exploring": 9}
{"steps": 71554, "episode reward": 1767.0, "episodes": 301, "mean 100 episode reward": 955.2, "% time spent exploring": 9}
{"steps": 71705, "episode reward": 765.0, "episodes": 302, "mean 100 episode reward": 955.5, "% time spent exploring": 9}
{"steps": 71868, "episode reward": 1210.0, "episodes": 303, "mean 100 episode reward": 948.5, "% time spent exploring": 9}
{"steps": 71895, "episode reward": 238.0, "episodes": 304, "mean 100 episode reward": 943.3, "% time spent exploring": 9}
{"steps": 72054, "episode reward": 1238.0, "episodes": 305, "mean 100 episode reward": 934.9, "% time spent exploring": 9}
{"steps": 72216, "episode reward": 1139.0, "episodes": 306, "mean 100 episode reward": 940.1, "% time spent exploring": 9}
{"steps": 72470, "episode reward": 1835.0, "episodes": 307, "mean 100 episode reward": 948.2, "% time spent exploring": 9}
{"steps": 72569, "episode reward": 606.0, "episodes": 308, "mean 100 episode reward": 943.9, "% time spent exploring": 9}
{"steps": 72728, "episode reward": 1209.0, "episodes": 309, "mean 100 episode reward": 941.9, "% time spent exploring": 9}
{"steps": 72987, "episode reward": 1400.0, "episodes": 310, "mean 100 episode reward": 953.6, "% time spent exploring": 9}
{"steps": 73389, "episode reward": 1128.0, "episodes": 311, "mean 100 episode reward": 948.4, "% time spent exploring": 9}
{"steps": 73564, "episode reward": 1314.0, "episodes": 312, "mean 100 episode reward": 959.2, "% time spent exploring": 9}
{"steps": 73595, "episode reward": 155.0, "episodes": 313, "mean 100 episode reward": 952.7, "% time spent exploring": 9}
{"steps": 73835, "episode reward": 1678.0, "episodes": 314, "mean 100 episode reward": 958.2, "% time spent exploring": 9}
{"steps": 73866, "episode reward": 169.0, "episodes": 315, "mean 100 episode reward": 947.4, "% time spent exploring": 9}
{"steps": 74012, "episode reward": 1142.0, "episodes": 316, "mean 100 episode reward": 946.6, "% time spent exploring": 9}
{"steps": 74215, "episode reward": 1652.0, "episodes": 317, "mean 100 episode reward": 961.8, "% time spent exploring": 9}
{"steps": 74292, "episode reward": 587.0, "episodes": 318, "mean 100 episode reward": 960.5, "% time spent exploring": 9}
{"steps": 74649, "episode reward": 2430.0, "episodes": 319, "mean 100 episode reward": 970.9, "% time spent exploring": 9}
{"steps": 74799, "episode reward": 804.0, "episodes": 320, "mean 100 episode reward": 965.9, "% time spent exploring": 9}
{"steps": 74969, "episode reward": 1394.0, "episodes": 321, "mean 100 episode reward": 977.7, "% time spent exploring": 9}
{"steps": 75270, "episode reward": 1835.0, "episodes": 322, "mean 100 episode reward": 993.7, "% time spent exploring": 9}
{"steps": 75327, "episode reward": 382.0, "episodes": 323, "mean 100 episode reward": 983.6, "% time spent exploring": 9}
{"steps": 75394, "episode reward": 591.0, "episodes": 324, "mean 100 episode reward": 983.2, "% time spent exploring": 9}
{"steps": 75654, "episode reward": 1998.0, "episodes": 325, "mean 100 episode reward": 981.5, "% time spent exploring": 9}
{"steps": 75791, "episode reward": 1338.0, "episodes": 326, "mean 100 episode reward": 988.7, "% time spent exploring": 9}
{"steps": 75956, "episode reward": 1232.0, "episodes": 327, "mean 100 episode reward": 984.6, "% time spent exploring": 9}
{"steps": 76076, "episode reward": 1037.0, "episodes": 328, "mean 100 episode reward": 987.4, "% time spent exploring": 9}
{"steps": 76288, "episode reward": 1415.0, "episodes": 329, "mean 100 episode reward": 993.5, "% time spent exploring": 9}
{"steps": 76315, "episode reward": 239.0, "episodes": 330, "mean 100 episode reward": 982.8, "% time spent exploring": 9}
{"steps": 76508, "episode reward": 1641.0, "episodes": 331, "mean 100 episode reward": 997.6, "% time spent exploring": 9}
{"steps": 76702, "episode reward": 795.0, "episodes": 332, "mean 100 episode reward": 995.4, "% time spent exploring": 9}
{"steps": 76858, "episode reward": 1183.0, "episodes": 333, "mean 100 episode reward": 995.1, "% time spent exploring": 9}
{"steps": 76933, "episode reward": 599.0, "episodes": 334, "mean 100 episode reward": 995.1, "% time spent exploring": 9}
{"steps": 77137, "episode reward": 1628.0, "episodes": 335, "mean 100 episode reward": 995.8, "% time spent exploring": 9}
{"steps": 77267, "episode reward": 578.0, "episodes": 336, "mean 100 episode reward": 978.9, "% time spent exploring": 9}
{"steps": 77521, "episode reward": 1624.0, "episodes": 337, "mean 100 episode reward": 993.5, "% time spent exploring": 9}
{"steps": 77760, "episode reward": 1846.0, "episodes": 338, "mean 100 episode reward": 1009.7, "% time spent exploring": 9}
{"steps": 77794, "episode reward": 105.0, "episodes": 339, "mean 100 episode reward": 994.5, "% time spent exploring": 9}
{"steps": 77923, "episode reward": 729.0, "episodes": 340, "mean 100 episode reward": 993.8, "% time spent exploring": 9}
{"steps": 78016, "episode reward": 827.0, "episodes": 341, "mean 100 episode reward": 993.7, "% time spent exploring": 9}
{"steps": 78043, "episode reward": 234.0, "episodes": 342, "mean 100 episode reward": 986.0, "% time spent exploring": 9}
{"steps": 78341, "episode reward": 1653.0, "episodes": 343, "mean 100 episode reward": 988.5, "% time spent exploring": 9}
{"steps": 78752, "episode reward": 1264.0, "episodes": 344, "mean 100 episode reward": 993.8, "% time spent exploring": 9}
{"steps": 78828, "episode reward": 690.0, "episodes": 345, "mean 100 episode reward": 992.5, "% time spent exploring": 9}
{"steps": 78901, "episode reward": 604.0, "episodes": 346, "mean 100 episode reward": 992.2, "% time spent exploring": 9}
{"steps": 79147, "episode reward": 1610.0, "episodes": 347, "mean 100 episode reward": 993.7, "% time spent exploring": 9}
{"steps": 79176, "episode reward": 223.0, "episodes": 348, "mean 100 episode reward": 990.0, "% time spent exploring": 9}
{"steps": 79505, "episode reward": 1891.0, "episodes": 349, "mean 100 episode reward": 992.8, "% time spent exploring": 9}
{"steps": 79859, "episode reward": 1534.0, "episodes": 350, "mean 100 episode reward": 1002.4, "% time spent exploring": 9}
{"steps": 79893, "episode reward": 158.0, "episodes": 351, "mean 100 episode reward": 995.7, "% time spent exploring": 9}
{"steps": 80123, "episode reward": 1314.0, "episodes": 352, "mean 100 episode reward": 1002.7, "% time spent exploring": 9}
{"steps": 80219, "episode reward": 669.0, "episodes": 353, "mean 100 episode reward": 993.6, "% time spent exploring": 9}
{"steps": 80330, "episode reward": 1039.0, "episodes": 354, "mean 100 episode reward": 1001.8, "% time spent exploring": 9}
{"steps": 80664, "episode reward": 1864.0, "episodes": 355, "mean 100 episode reward": 1004.4, "% time spent exploring": 9}
{"steps": 80696, "episode reward": 224.0, "episodes": 356, "mean 100 episode reward": 1000.7, "% time spent exploring": 9}
{"steps": 80837, "episode reward": 968.0, "episodes": 357, "mean 100 episode reward": 995.1, "% time spent exploring": 9}
{"steps": 81095, "episode reward": 1405.0, "episodes": 358, "mean 100 episode reward": 1003.0, "% time spent exploring": 9}
{"steps": 81136, "episode reward": 213.0, "episodes": 359, "mean 100 episode reward": 987.8, "% time spent exploring": 9}
{"steps": 81223, "episode reward": 603.0, "episodes": 360, "mean 100 episode reward": 979.8, "% time spent exploring": 9}
{"steps": 81512, "episode reward": 1861.0, "episodes": 361, "mean 100 episode reward": 996.8, "% time spent exploring": 9}
{"steps": 81640, "episode reward": 1030.0, "episodes": 362, "mean 100 episode reward": 1000.9, "% time spent exploring": 9}
{"steps": 82059, "episode reward": 1853.0, "episodes": 363, "mean 100 episode reward": 1003.4, "% time spent exploring": 9}
{"steps": 82128, "episode reward": 601.0, "episodes": 364, "mean 100 episode reward": 1003.4, "% time spent exploring": 9}
{"steps": 82521, "episode reward": 2034.0, "episodes": 365, "mean 100 episode reward": 1007.5, "% time spent exploring": 9}
{"steps": 82690, "episode reward": 1318.0, "episodes": 366, "mean 100 episode reward": 1007.4, "% time spent exploring": 9}
{"steps": 82769, "episode reward": 682.0, "episodes": 367, "mean 100 episode reward": 1012.8, "% time spent exploring": 9}
{"steps": 82796, "episode reward": 232.0, "episodes": 368, "mean 100 episode reward": 1009.0, "% time spent exploring": 9}
{"steps": 82949, "episode reward": 1227.0, "episodes": 369, "mean 100 episode reward": 1007.7, "% time spent exploring": 9}
{"steps": 83026, "episode reward": 591.0, "episodes": 370, "mean 100 episode reward": 1007.6, "% time spent exploring": 9}
{"steps": 83212, "episode reward": 1034.0, "episodes": 371, "mean 100 episode reward": 1009.8, "% time spent exploring": 9}
{"steps": 83299, "episode reward": 619.0, "episodes": 372, "mean 100 episode reward": 1007.9, "% time spent exploring": 9}
{"steps": 83740, "episode reward": 2019.0, "episodes": 373, "mean 100 episode reward": 1019.7, "% time spent exploring": 9}
{"steps": 83817, "episode reward": 610.0, "episodes": 374, "mean 100 episode reward": 1014.5, "% time spent exploring": 9}
{"steps": 84093, "episode reward": 2068.0, "episodes": 375, "mean 100 episode reward": 1030.6, "% time spent exploring": 9}
{"steps": 84340, "episode reward": 1314.0, "episodes": 376, "mean 100 episode reward": 1041.3, "% time spent exploring": 9}
{"steps": 84386, "episode reward": 204.0, "episodes": 377, "mean 100 episode reward": 1033.0, "% time spent exploring": 9}
{"steps": 84414, "episode reward": 233.0, "episodes": 378, "mean 100 episode reward": 1025.1, "% time spent exploring": 9}
{"steps": 84795, "episode reward": 2951.0, "episodes": 379, "mean 100 episode reward": 1038.4, "% time spent exploring": 9}
{"steps": 84890, "episode reward": 600.0, "episodes": 380, "mean 100 episode reward": 1034.8, "% time spent exploring": 9}
{"steps": 85230, "episode reward": 2065.0, "episodes": 381, "mean 100 episode reward": 1035.8, "% time spent exploring": 9}
{"steps": 85327, "episode reward": 599.0, "episodes": 382, "mean 100 episode reward": 1036.0, "% time spent exploring": 9}
{"steps": 85548, "episode reward": 1542.0, "episodes": 383, "mean 100 episode reward": 1043.1, "% time spent exploring": 9}
{"steps": 85625, "episode reward": 615.0, "episodes": 384, "mean 100 episode reward": 1043.4, "% time spent exploring": 9}
{"steps": 85945, "episode reward": 1826.0, "episodes": 385, "mean 100 episode reward": 1053.2, "% time spent exploring": 9}
{"steps": 86029, "episode reward": 615.0, "episodes": 386, "mean 100 episode reward": 1051.4, "% time spent exploring": 9}
{"steps": 86237, "episode reward": 1654.0, "episodes": 387, "mean 100 episode reward": 1049.7, "% time spent exploring": 9}
{"steps": 86418, "episode reward": 1555.0, "episodes": 388, "mean 100 episode reward": 1063.0, "% time spent exploring": 9}
{"steps": 86475, "episode reward": 376.0, "episodes": 389, "mean 100 episode reward": 1051.4, "% time spent exploring": 9}
{"steps": 86686, "episode reward": 704.0, "episodes": 390, "mean 100 episode reward": 1056.3, "% time spent exploring": 9}
{"steps": 86973, "episode reward": 2058.0, "episodes": 391, "mean 100 episode reward": 1064.6, "% time spent exploring": 9}
{"steps": 87039, "episode reward": 615.0, "episodes": 392, "mean 100 episode reward": 1064.8, "% time spent exploring": 9}
{"steps": 87336, "episode reward": 1953.0, "episodes": 393, "mean 100 episode reward": 1075.6, "% time spent exploring": 9}
{"steps": 87415, "episode reward": 601.0, "episodes": 394, "mean 100 episode reward": 1075.6, "% time spent exploring": 9}
{"steps": 87514, "episode reward": 831.0, "episodes": 395, "mean 100 episode reward": 1075.8, "% time spent exploring": 9}
{"steps": 87647, "episode reward": 631.0, "episodes": 396, "mean 100 episode reward": 1068.9, "% time spent exploring": 9}
{"steps": 88002, "episode reward": 2351.0, "episodes": 397, "mean 100 episode reward": 1091.1, "% time spent exploring": 9}
{"steps": 88161, "episode reward": 1333.0, "episodes": 398, "mean 100 episode reward": 1102.1, "% time spent exploring": 9}
{"steps": 88214, "episode reward": 367.0, "episodes": 399, "mean 100 episode reward": 1092.5, "% time spent exploring": 9}
{"steps": 88297, "episode reward": 615.0, "episodes": 400, "mean 100 episode reward": 1096.3, "% time spent exploring": 9}
{"steps": 88536, "episode reward": 1740.0, "episodes": 401, "mean 100 episode reward": 1096.0, "% time spent exploring": 9}
{"steps": 88603, "episode reward": 603.0, "episodes": 402, "mean 100 episode reward": 1094.4, "% time spent exploring": 9}
{"steps": 88895, "episode reward": 999.0, "episodes": 403, "mean 100 episode reward": 1092.3, "% time spent exploring": 9}
{"steps": 89084, "episode reward": 796.0, "episodes": 404, "mean 100 episode reward": 1097.9, "% time spent exploring": 9}
{"steps": 89307, "episode reward": 1727.0, "episodes": 405, "mean 100 episode reward": 1102.8, "% time spent exploring": 9}
{"steps": 89385, "episode reward": 618.0, "episodes": 406, "mean 100 episode reward": 1097.6, "% time spent exploring": 9}
{"steps": 89715, "episode reward": 2215.0, "episodes": 407, "mean 100 episode reward": 1101.4, "% time spent exploring": 9}
{"steps": 89747, "episode reward": 220.0, "episodes": 408, "mean 100 episode reward": 1097.5, "% time spent exploring": 9}
{"steps": 90399, "episode reward": 2858.0, "episodes": 409, "mean 100 episode reward": 1114.0, "% time spent exploring": 9}
{"steps": 90541, "episode reward": 1032.0, "episodes": 410, "mean 100 episode reward": 1110.3, "% time spent exploring": 9}
{"steps": 90757, "episode reward": 1254.0, "episodes": 411, "mean 100 episode reward": 1111.6, "% time spent exploring": 9}
{"steps": 90988, "episode reward": 1411.0, "episodes": 412, "mean 100 episode reward": 1112.5, "% time spent exploring": 9}
{"steps": 91087, "episode reward": 961.0, "episodes": 413, "mean 100 episode reward": 1120.6, "% time spent exploring": 9}
{"steps": 91540, "episode reward": 661.0, "episodes": 414, "mean 100 episode reward": 1110.4, "% time spent exploring": 9}
{"steps": 91779, "episode reward": 1300.0, "episodes": 415, "mean 100 episode reward": 1121.7, "% time spent exploring": 9}
{"steps": 91915, "episode reward": 630.0, "episodes": 416, "mean 100 episode reward": 1116.6, "% time spent exploring": 9}
{"steps": 92185, "episode reward": 1936.0, "episodes": 417, "mean 100 episode reward": 1119.4, "% time spent exploring": 9}
{"steps": 92367, "episode reward": 797.0, "episodes": 418, "mean 100 episode reward": 1121.6, "% time spent exploring": 9}
{"steps": 92810, "episode reward": 2462.0, "episodes": 419, "mean 100 episode reward": 1121.9, "% time spent exploring": 9}
{"steps": 93025, "episode reward": 1413.0, "episodes": 420, "mean 100 episode reward": 1128.0, "% time spent exploring": 9}
{"steps": 93129, "episode reward": 905.0, "episodes": 421, "mean 100 episode reward": 1123.1, "% time spent exploring": 9}
{"steps": 93246, "episode reward": 1141.0, "episodes": 422, "mean 100 episode reward": 1116.1, "% time spent exploring": 9}
{"steps": 93744, "episode reward": 2383.0, "episodes": 423, "mean 100 episode reward": 1136.1, "% time spent exploring": 9}
{"steps": 93886, "episode reward": 805.0, "episodes": 424, "mean 100 episode reward": 1138.3, "% time spent exploring": 9}
{"steps": 94207, "episode reward": 1232.0, "episodes": 425, "mean 100 episode reward": 1130.6, "% time spent exploring": 9}
{"steps": 94474, "episode reward": 1397.0, "episodes": 426, "mean 100 episode reward": 1131.2, "% time spent exploring": 9}
{"steps": 94519, "episode reward": 213.0, "episodes": 427, "mean 100 episode reward": 1121.0, "% time spent exploring": 9}
{"steps": 94688, "episode reward": 1027.0, "episodes": 428, "mean 100 episode reward": 1120.9, "% time spent exploring": 9}
{"steps": 95024, "episode reward": 1904.0, "episodes": 429, "mean 100 episode reward": 1125.8, "% time spent exploring": 9}
{"steps": 95190, "episode reward": 1316.0, "episodes": 430, "mean 100 episode reward": 1136.6, "% time spent exploring": 9}
{"steps": 95276, "episode reward": 733.0, "episodes": 431, "mean 100 episode reward": 1127.5, "% time spent exploring": 9}
{"steps": 95438, "episode reward": 1554.0, "episodes": 432, "mean 100 episode reward": 1135.1, "% time spent exploring": 9}
{"steps": 95550, "episode reward": 969.0, "episodes": 433, "mean 100 episode reward": 1133.0, "% time spent exploring": 9}
{"steps": 95806, "episode reward": 1297.0, "episodes": 434, "mean 100 episode reward": 1139.9, "% time spent exploring": 9}
{"steps": 95996, "episode reward": 1395.0, "episodes": 435, "mean 100 episode reward": 1137.6, "% time spent exploring": 9}
{"steps": 97067, "episode reward": 1149.0, "episodes": 436, "mean 100 episode reward": 1143.3, "% time spent exploring": 9}
{"steps": 97174, "episode reward": 847.0, "episodes": 437, "mean 100 episode reward": 1135.5, "% time spent exploring": 9}
{"steps": 97329, "episode reward": 1031.0, "episodes": 438, "mean 100 episode reward": 1127.4, "% time spent exploring": 9}
{"steps": 97564, "episode reward": 1346.0, "episodes": 439, "mean 100 episode reward": 1139.8, "% time spent exploring": 9}
{"steps": 97591, "episode reward": 239.0, "episodes": 440, "mean 100 episode reward": 1134.9, "% time spent exploring": 9}
{"steps": 97840, "episode reward": 1548.0, "episodes": 441, "mean 100 episode reward": 1142.1, "% time spent exploring": 9}
{"steps": 98059, "episode reward": 1038.0, "episodes": 442, "mean 100 episode reward": 1150.2, "% time spent exploring": 9}
{"steps": 98373, "episode reward": 1657.0, "episodes": 443, "mean 100 episode reward": 1150.2, "% time spent exploring": 9}
{"steps": 98431, "episode reward": 597.0, "episodes": 444, "mean 100 episode reward": 1143.5, "% time spent exploring": 9}
{"steps": 98589, "episode reward": 1489.0, "episodes": 445, "mean 100 episode reward": 1151.5, "% time spent exploring": 9}
{"steps": 98621, "episode reward": 237.0, "episodes": 446, "mean 100 episode reward": 1147.8, "% time spent exploring": 9}
{"steps": 98780, "episode reward": 1267.0, "episodes": 447, "mean 100 episode reward": 1144.4, "% time spent exploring": 9}
{"steps": 98851, "episode reward": 597.0, "episodes": 448, "mean 100 episode reward": 1148.2, "% time spent exploring": 9}
{"steps": 99059, "episode reward": 1470.0, "episodes": 449, "mean 100 episode reward": 1143.9, "% time spent exploring": 9}
{"steps": 99117, "episode reward": 591.0, "episodes": 450, "mean 100 episode reward": 1134.5, "% time spent exploring": 9}
{"steps": 99318, "episode reward": 1657.0, "episodes": 451, "mean 100 episode reward": 1149.5, "% time spent exploring": 9}
{"steps": 99564, "episode reward": 1010.0, "episodes": 452, "mean 100 episode reward": 1146.5, "% time spent exploring": 9}
