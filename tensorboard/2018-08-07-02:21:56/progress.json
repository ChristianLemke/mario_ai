{"steps": 2882, "mean 100 episode reward": 1334.0, "episodes": 2, "% time spent exploring": 99}
{"steps": 4688, "mean 100 episode reward": 1565.0, "episodes": 3, "% time spent exploring": 99}
{"steps": 5319, "mean 100 episode reward": 1517.3, "episodes": 4, "% time spent exploring": 98}
{"steps": 7419, "mean 100 episode reward": 1301.0, "episodes": 5, "% time spent exploring": 98}
{"steps": 8311, "mean 100 episode reward": 1374.0, "episodes": 6, "% time spent exploring": 98}
{"steps": 10131, "mean 100 episode reward": 1403.7, "episodes": 7, "% time spent exploring": 97}
{"steps": 10316, "mean 100 episode reward": 1287.4, "episodes": 8, "% time spent exploring": 97}
{"steps": 11686, "mean 100 episode reward": 1282.2, "episodes": 9, "% time spent exploring": 97}
{"steps": 12416, "mean 100 episode reward": 1374.4, "episodes": 10, "% time spent exploring": 97}
{"steps": 13093, "mean 100 episode reward": 1447.3, "episodes": 11, "% time spent exploring": 97}
{"steps": 14639, "mean 100 episode reward": 1436.1, "episodes": 12, "% time spent exploring": 97}
{"steps": 15681, "mean 100 episode reward": 1449.8, "episodes": 13, "% time spent exploring": 96}
{"steps": 16635, "mean 100 episode reward": 1523.8, "episodes": 14, "% time spent exploring": 96}
{"steps": 17955, "mean 100 episode reward": 1562.4, "episodes": 15, "% time spent exploring": 96}
{"steps": 18851, "mean 100 episode reward": 1566.6, "episodes": 16, "% time spent exploring": 96}
{"steps": 19639, "mean 100 episode reward": 1591.6, "episodes": 17, "% time spent exploring": 96}
{"steps": 20025, "mean 100 episode reward": 1585.6, "episodes": 18, "% time spent exploring": 95}
{"steps": 21674, "mean 100 episode reward": 1594.9, "episodes": 19, "% time spent exploring": 95}
{"steps": 24072, "mean 100 episode reward": 1627.8, "episodes": 20, "% time spent exploring": 95}
{"steps": 24874, "mean 100 episode reward": 1639.7, "episodes": 21, "% time spent exploring": 95}
{"steps": 25369, "mean 100 episode reward": 1630.1, "episodes": 22, "% time spent exploring": 94}
{"steps": 25978, "mean 100 episode reward": 1630.0, "episodes": 23, "% time spent exploring": 94}
{"steps": 29326, "mean 100 episode reward": 1671.7, "episodes": 24, "% time spent exploring": 94}
{"steps": 29750, "mean 100 episode reward": 1677.6, "episodes": 25, "% time spent exploring": 94}
{"steps": 31518, "mean 100 episode reward": 1674.2, "episodes": 26, "% time spent exploring": 93}
{"steps": 32313, "mean 100 episode reward": 1684.5, "episodes": 27, "% time spent exploring": 93}
{"steps": 33065, "mean 100 episode reward": 1680.6, "episodes": 28, "% time spent exploring": 93}
{"steps": 33600, "mean 100 episode reward": 1671.0, "episodes": 29, "% time spent exploring": 93}
{"steps": 34362, "mean 100 episode reward": 1686.3, "episodes": 30, "% time spent exploring": 93}
{"steps": 35306, "mean 100 episode reward": 1709.3, "episodes": 31, "% time spent exploring": 92}
{"steps": 35763, "mean 100 episode reward": 1703.5, "episodes": 32, "% time spent exploring": 92}
{"steps": 37662, "mean 100 episode reward": 1705.1, "episodes": 33, "% time spent exploring": 92}
{"steps": 38141, "mean 100 episode reward": 1709.5, "episodes": 34, "% time spent exploring": 92}
{"steps": 40692, "mean 100 episode reward": 1726.4, "episodes": 35, "% time spent exploring": 91}
{"steps": 41514, "mean 100 episode reward": 1728.3, "episodes": 36, "% time spent exploring": 91}
{"steps": 42510, "mean 100 episode reward": 1717.0, "episodes": 37, "% time spent exploring": 91}
{"steps": 43069, "mean 100 episode reward": 1707.8, "episodes": 38, "% time spent exploring": 91}
{"steps": 44268, "mean 100 episode reward": 1689.3, "episodes": 39, "% time spent exploring": 91}
{"steps": 44837, "mean 100 episode reward": 1691.9, "episodes": 40, "% time spent exploring": 91}
{"steps": 45173, "mean 100 episode reward": 1674.6, "episodes": 41, "% time spent exploring": 90}
{"steps": 46146, "mean 100 episode reward": 1679.0, "episodes": 42, "% time spent exploring": 90}
{"steps": 46548, "mean 100 episode reward": 1668.3, "episodes": 43, "% time spent exploring": 90}
{"steps": 46967, "mean 100 episode reward": 1657.7, "episodes": 44, "% time spent exploring": 90}
{"steps": 48736, "mean 100 episode reward": 1684.5, "episodes": 45, "% time spent exploring": 90}
{"steps": 49342, "mean 100 episode reward": 1681.3, "episodes": 46, "% time spent exploring": 90}
{"steps": 50900, "mean 100 episode reward": 1680.4, "episodes": 47, "% time spent exploring": 89}
{"steps": 52859, "mean 100 episode reward": 1681.8, "episodes": 48, "% time spent exploring": 89}
{"steps": 53236, "mean 100 episode reward": 1668.0, "episodes": 49, "% time spent exploring": 89}
{"steps": 54181, "mean 100 episode reward": 1676.3, "episodes": 50, "% time spent exploring": 89}
{"steps": 55240, "mean 100 episode reward": 1689.0, "episodes": 51, "% time spent exploring": 88}
{"steps": 56177, "mean 100 episode reward": 1695.2, "episodes": 52, "% time spent exploring": 88}
{"steps": 57144, "mean 100 episode reward": 1710.4, "episodes": 53, "% time spent exploring": 88}
{"steps": 57400, "mean 100 episode reward": 1700.9, "episodes": 54, "% time spent exploring": 88}
{"steps": 58406, "mean 100 episode reward": 1731.0, "episodes": 55, "% time spent exploring": 88}
{"steps": 58831, "mean 100 episode reward": 1732.1, "episodes": 56, "% time spent exploring": 88}
{"steps": 59084, "mean 100 episode reward": 1719.4, "episodes": 57, "% time spent exploring": 88}
{"steps": 60451, "mean 100 episode reward": 1710.9, "episodes": 58, "% time spent exploring": 87}
{"steps": 60658, "mean 100 episode reward": 1698.5, "episodes": 59, "% time spent exploring": 87}
{"steps": 61862, "mean 100 episode reward": 1710.9, "episodes": 60, "% time spent exploring": 87}
{"steps": 63170, "mean 100 episode reward": 1711.6, "episodes": 61, "% time spent exploring": 87}
{"steps": 63799, "mean 100 episode reward": 1706.5, "episodes": 62, "% time spent exploring": 87}
{"steps": 64275, "mean 100 episode reward": 1704.1, "episodes": 63, "% time spent exploring": 87}
{"steps": 65301, "mean 100 episode reward": 1706.3, "episodes": 64, "% time spent exploring": 86}
{"steps": 66773, "mean 100 episode reward": 1718.0, "episodes": 65, "% time spent exploring": 86}
{"steps": 67641, "mean 100 episode reward": 1729.0, "episodes": 66, "% time spent exploring": 86}
{"steps": 68690, "mean 100 episode reward": 1731.9, "episodes": 67, "% time spent exploring": 86}
{"steps": 69429, "mean 100 episode reward": 1734.4, "episodes": 68, "% time spent exploring": 86}
{"steps": 69656, "mean 100 episode reward": 1724.6, "episodes": 69, "% time spent exploring": 86}
{"steps": 69781, "mean 100 episode reward": 1709.3, "episodes": 70, "% time spent exploring": 86}
{"steps": 70750, "mean 100 episode reward": 1704.7, "episodes": 71, "% time spent exploring": 85}
{"steps": 71567, "mean 100 episode reward": 1706.1, "episodes": 72, "% time spent exploring": 85}
{"steps": 72115, "mean 100 episode reward": 1700.8, "episodes": 73, "% time spent exploring": 85}
{"steps": 73600, "mean 100 episode reward": 1701.0, "episodes": 74, "% time spent exploring": 85}
{"steps": 75240, "mean 100 episode reward": 1703.7, "episodes": 75, "% time spent exploring": 84}
{"steps": 75484, "mean 100 episode reward": 1694.2, "episodes": 76, "% time spent exploring": 84}
{"steps": 75820, "mean 100 episode reward": 1685.1, "episodes": 77, "% time spent exploring": 84}
{"steps": 78137, "mean 100 episode reward": 1696.8, "episodes": 78, "% time spent exploring": 84}
{"steps": 78779, "mean 100 episode reward": 1702.5, "episodes": 79, "% time spent exploring": 84}
{"steps": 80338, "mean 100 episode reward": 1709.6, "episodes": 80, "% time spent exploring": 83}
{"steps": 81134, "mean 100 episode reward": 1714.1, "episodes": 81, "% time spent exploring": 83}
{"steps": 81540, "mean 100 episode reward": 1713.3, "episodes": 82, "% time spent exploring": 83}
{"steps": 83892, "mean 100 episode reward": 1715.2, "episodes": 83, "% time spent exploring": 83}
{"steps": 84519, "mean 100 episode reward": 1716.2, "episodes": 84, "% time spent exploring": 83}
{"steps": 84998, "mean 100 episode reward": 1709.1, "episodes": 85, "% time spent exploring": 83}
{"steps": 85307, "mean 100 episode reward": 1705.7, "episodes": 86, "% time spent exploring": 82}
{"steps": 85864, "mean 100 episode reward": 1702.3, "episodes": 87, "% time spent exploring": 82}
{"steps": 86270, "mean 100 episode reward": 1702.9, "episodes": 88, "% time spent exploring": 82}
{"steps": 86875, "mean 100 episode reward": 1700.7, "episodes": 89, "% time spent exploring": 82}
{"steps": 88088, "mean 100 episode reward": 1704.6, "episodes": 90, "% time spent exploring": 82}
{"steps": 88770, "mean 100 episode reward": 1702.6, "episodes": 91, "% time spent exploring": 82}
{"steps": 88946, "mean 100 episode reward": 1695.1, "episodes": 92, "% time spent exploring": 82}
{"steps": 89336, "mean 100 episode reward": 1692.1, "episodes": 93, "% time spent exploring": 82}
{"steps": 89703, "mean 100 episode reward": 1693.4, "episodes": 94, "% time spent exploring": 82}
{"steps": 90596, "mean 100 episode reward": 1696.7, "episodes": 95, "% time spent exploring": 81}
{"steps": 91006, "mean 100 episode reward": 1696.0, "episodes": 96, "% time spent exploring": 81}
{"steps": 92288, "mean 100 episode reward": 1695.7, "episodes": 97, "% time spent exploring": 81}
{"steps": 93259, "mean 100 episode reward": 1701.3, "episodes": 98, "% time spent exploring": 81}
{"steps": 93707, "mean 100 episode reward": 1699.9, "episodes": 99, "% time spent exploring": 81}
{"steps": 94058, "mean 100 episode reward": 1696.4, "episodes": 100, "% time spent exploring": 81}
{"steps": 94677, "mean 100 episode reward": 1700.9, "episodes": 101, "% time spent exploring": 81}
{"steps": 95106, "mean 100 episode reward": 1702.3, "episodes": 102, "% time spent exploring": 80}
{"steps": 95711, "mean 100 episode reward": 1699.8, "episodes": 103, "% time spent exploring": 80}
{"steps": 97214, "mean 100 episode reward": 1709.1, "episodes": 104, "% time spent exploring": 80}
{"steps": 97819, "mean 100 episode reward": 1720.9, "episodes": 105, "% time spent exploring": 80}
{"steps": 98004, "mean 100 episode reward": 1714.7, "episodes": 106, "% time spent exploring": 80}
{"steps": 98808, "mean 100 episode reward": 1712.3, "episodes": 107, "% time spent exploring": 80}
{"steps": 99578, "mean 100 episode reward": 1726.0, "episodes": 108, "% time spent exploring": 80}
{"steps": 100154, "mean 100 episode reward": 1727.0, "episodes": 109, "% time spent exploring": 79}
{"steps": 100559, "mean 100 episode reward": 1719.7, "episodes": 110, "% time spent exploring": 79}
{"steps": 101251, "mean 100 episode reward": 1717.8, "episodes": 111, "% time spent exploring": 79}
{"steps": 102675, "mean 100 episode reward": 1723.3, "episodes": 112, "% time spent exploring": 79}
{"steps": 103473, "mean 100 episode reward": 1726.7, "episodes": 113, "% time spent exploring": 79}
{"steps": 104200, "mean 100 episode reward": 1726.1, "episodes": 114, "% time spent exploring": 79}
{"steps": 104938, "mean 100 episode reward": 1719.9, "episodes": 115, "% time spent exploring": 79}
{"steps": 105287, "mean 100 episode reward": 1718.6, "episodes": 116, "% time spent exploring": 78}
{"steps": 105880, "mean 100 episode reward": 1712.6, "episodes": 117, "% time spent exploring": 78}
{"steps": 106909, "mean 100 episode reward": 1714.7, "episodes": 118, "% time spent exploring": 78}
{"steps": 107281, "mean 100 episode reward": 1711.3, "episodes": 119, "% time spent exploring": 78}
{"steps": 109358, "mean 100 episode reward": 1714.6, "episodes": 120, "% time spent exploring": 78}
{"steps": 109861, "mean 100 episode reward": 1710.8, "episodes": 121, "% time spent exploring": 78}
{"steps": 110694, "mean 100 episode reward": 1722.5, "episodes": 122, "% time spent exploring": 77}
{"steps": 111140, "mean 100 episode reward": 1722.0, "episodes": 123, "% time spent exploring": 77}
{"steps": 111924, "mean 100 episode reward": 1716.5, "episodes": 124, "% time spent exploring": 77}
{"steps": 113047, "mean 100 episode reward": 1717.0, "episodes": 125, "% time spent exploring": 77}
{"steps": 113590, "mean 100 episode reward": 1715.9, "episodes": 126, "% time spent exploring": 77}
{"steps": 114341, "mean 100 episode reward": 1716.7, "episodes": 127, "% time spent exploring": 77}
{"steps": 115146, "mean 100 episode reward": 1724.4, "episodes": 128, "% time spent exploring": 76}
{"steps": 115764, "mean 100 episode reward": 1735.1, "episodes": 129, "% time spent exploring": 76}
{"steps": 116566, "mean 100 episode reward": 1732.1, "episodes": 130, "% time spent exploring": 76}
{"steps": 117044, "mean 100 episode reward": 1726.4, "episodes": 131, "% time spent exploring": 76}
{"steps": 117502, "mean 100 episode reward": 1723.5, "episodes": 132, "% time spent exploring": 76}
{"steps": 117894, "mean 100 episode reward": 1719.7, "episodes": 133, "% time spent exploring": 76}
{"steps": 118142, "mean 100 episode reward": 1711.7, "episodes": 134, "% time spent exploring": 76}
{"steps": 118874, "mean 100 episode reward": 1707.3, "episodes": 135, "% time spent exploring": 76}
{"steps": 119800, "mean 100 episode reward": 1708.4, "episodes": 136, "% time spent exploring": 76}
{"steps": 120087, "mean 100 episode reward": 1706.9, "episodes": 137, "% time spent exploring": 75}
{"steps": 120727, "mean 100 episode reward": 1715.0, "episodes": 138, "% time spent exploring": 75}
{"steps": 121817, "mean 100 episode reward": 1731.6, "episodes": 139, "% time spent exploring": 75}
{"steps": 122519, "mean 100 episode reward": 1727.0, "episodes": 140, "% time spent exploring": 75}
{"steps": 123038, "mean 100 episode reward": 1730.6, "episodes": 141, "% time spent exploring": 75}
{"steps": 123841, "mean 100 episode reward": 1726.5, "episodes": 142, "% time spent exploring": 75}
{"steps": 124300, "mean 100 episode reward": 1728.9, "episodes": 143, "% time spent exploring": 75}
{"steps": 124739, "mean 100 episode reward": 1731.3, "episodes": 144, "% time spent exploring": 75}
{"steps": 125386, "mean 100 episode reward": 1726.0, "episodes": 145, "% time spent exploring": 74}
{"steps": 125955, "mean 100 episode reward": 1728.9, "episodes": 146, "% time spent exploring": 74}
{"steps": 126968, "mean 100 episode reward": 1729.3, "episodes": 147, "% time spent exploring": 74}
{"steps": 127431, "mean 100 episode reward": 1726.2, "episodes": 148, "% time spent exploring": 74}
{"steps": 128149, "mean 100 episode reward": 1735.1, "episodes": 149, "% time spent exploring": 74}
{"steps": 128917, "mean 100 episode reward": 1736.0, "episodes": 150, "% time spent exploring": 74}
{"steps": 129434, "mean 100 episode reward": 1728.4, "episodes": 151, "% time spent exploring": 74}
{"steps": 129684, "mean 100 episode reward": 1718.3, "episodes": 152, "% time spent exploring": 74}
{"steps": 130088, "mean 100 episode reward": 1705.0, "episodes": 153, "% time spent exploring": 73}
{"steps": 130556, "mean 100 episode reward": 1708.8, "episodes": 154, "% time spent exploring": 73}
{"steps": 130673, "mean 100 episode reward": 1682.5, "episodes": 155, "% time spent exploring": 73}
{"steps": 131714, "mean 100 episode reward": 1687.8, "episodes": 156, "% time spent exploring": 73}
{"steps": 132783, "mean 100 episode reward": 1690.4, "episodes": 157, "% time spent exploring": 73}
{"steps": 133065, "mean 100 episode reward": 1689.6, "episodes": 158, "% time spent exploring": 73}
{"steps": 133907, "mean 100 episode reward": 1698.8, "episodes": 159, "% time spent exploring": 73}
{"steps": 134594, "mean 100 episode reward": 1686.2, "episodes": 160, "% time spent exploring": 73}
{"steps": 134950, "mean 100 episode reward": 1683.0, "episodes": 161, "% time spent exploring": 73}
{"steps": 135906, "mean 100 episode reward": 1687.7, "episodes": 162, "% time spent exploring": 72}
{"steps": 136573, "mean 100 episode reward": 1690.1, "episodes": 163, "% time spent exploring": 72}
{"steps": 137636, "mean 100 episode reward": 1691.4, "episodes": 164, "% time spent exploring": 72}
{"steps": 138100, "mean 100 episode reward": 1679.0, "episodes": 165, "% time spent exploring": 72}
{"steps": 138778, "mean 100 episode reward": 1670.7, "episodes": 166, "% time spent exploring": 72}
{"steps": 139373, "mean 100 episode reward": 1669.7, "episodes": 167, "% time spent exploring": 72}
{"steps": 139575, "mean 100 episode reward": 1661.5, "episodes": 168, "% time spent exploring": 72}
{"steps": 141349, "mean 100 episode reward": 1672.1, "episodes": 169, "% time spent exploring": 71}
{"steps": 141818, "mean 100 episode reward": 1679.9, "episodes": 170, "% time spent exploring": 71}
{"steps": 142150, "mean 100 episode reward": 1680.6, "episodes": 171, "% time spent exploring": 71}
{"steps": 143189, "mean 100 episode reward": 1688.6, "episodes": 172, "% time spent exploring": 71}
{"steps": 143877, "mean 100 episode reward": 1686.4, "episodes": 173, "% time spent exploring": 71}
{"steps": 144020, "mean 100 episode reward": 1675.8, "episodes": 174, "% time spent exploring": 71}
{"steps": 144325, "mean 100 episode reward": 1667.2, "episodes": 175, "% time spent exploring": 71}
{"steps": 145372, "mean 100 episode reward": 1682.9, "episodes": 176, "% time spent exploring": 70}
{"steps": 145894, "mean 100 episode reward": 1693.0, "episodes": 177, "% time spent exploring": 70}
{"steps": 146825, "mean 100 episode reward": 1687.1, "episodes": 178, "% time spent exploring": 70}
{"steps": 147108, "mean 100 episode reward": 1676.0, "episodes": 179, "% time spent exploring": 70}
{"steps": 147749, "mean 100 episode reward": 1681.3, "episodes": 180, "% time spent exploring": 70}
{"steps": 148926, "mean 100 episode reward": 1674.7, "episodes": 181, "% time spent exploring": 70}
{"steps": 149332, "mean 100 episode reward": 1672.3, "episodes": 182, "% time spent exploring": 70}
{"steps": 149884, "mean 100 episode reward": 1669.2, "episodes": 183, "% time spent exploring": 70}
{"steps": 150678, "mean 100 episode reward": 1674.6, "episodes": 184, "% time spent exploring": 69}
{"steps": 151014, "mean 100 episode reward": 1675.6, "episodes": 185, "% time spent exploring": 69}
{"steps": 151701, "mean 100 episode reward": 1680.8, "episodes": 186, "% time spent exploring": 69}
{"steps": 153342, "mean 100 episode reward": 1690.2, "episodes": 187, "% time spent exploring": 69}
{"steps": 153813, "mean 100 episode reward": 1687.1, "episodes": 188, "% time spent exploring": 69}
{"steps": 154423, "mean 100 episode reward": 1694.9, "episodes": 189, "% time spent exploring": 69}
{"steps": 155182, "mean 100 episode reward": 1695.7, "episodes": 190, "% time spent exploring": 68}
{"steps": 155619, "mean 100 episode reward": 1700.1, "episodes": 191, "% time spent exploring": 68}
{"steps": 156223, "mean 100 episode reward": 1707.6, "episodes": 192, "% time spent exploring": 68}
{"steps": 156556, "mean 100 episode reward": 1708.2, "episodes": 193, "% time spent exploring": 68}
{"steps": 157242, "mean 100 episode reward": 1711.6, "episodes": 194, "% time spent exploring": 68}
{"steps": 157752, "mean 100 episode reward": 1709.8, "episodes": 195, "% time spent exploring": 68}
{"steps": 158987, "mean 100 episode reward": 1715.0, "episodes": 196, "% time spent exploring": 68}
{"steps": 159406, "mean 100 episode reward": 1715.0, "episodes": 197, "% time spent exploring": 68}
{"steps": 160138, "mean 100 episode reward": 1709.8, "episodes": 198, "% time spent exploring": 67}
{"steps": 160694, "mean 100 episode reward": 1712.0, "episodes": 199, "% time spent exploring": 67}
{"steps": 160908, "mean 100 episode reward": 1708.7, "episodes": 200, "% time spent exploring": 67}
{"steps": 161097, "mean 100 episode reward": 1698.0, "episodes": 201, "% time spent exploring": 67}
{"steps": 162024, "mean 100 episode reward": 1707.0, "episodes": 202, "% time spent exploring": 67}
{"steps": 162339, "mean 100 episode reward": 1707.5, "episodes": 203, "% time spent exploring": 67}
{"steps": 163085, "mean 100 episode reward": 1705.8, "episodes": 204, "% time spent exploring": 67}
{"steps": 163684, "mean 100 episode reward": 1698.6, "episodes": 205, "% time spent exploring": 67}
{"steps": 164790, "mean 100 episode reward": 1707.1, "episodes": 206, "% time spent exploring": 67}
{"steps": 165499, "mean 100 episode reward": 1717.8, "episodes": 207, "% time spent exploring": 66}
{"steps": 165733, "mean 100 episode reward": 1708.9, "episodes": 208, "% time spent exploring": 66}
{"steps": 167047, "mean 100 episode reward": 1717.8, "episodes": 209, "% time spent exploring": 66}
{"steps": 168297, "mean 100 episode reward": 1728.0, "episodes": 210, "% time spent exploring": 66}
{"steps": 169026, "mean 100 episode reward": 1729.0, "episodes": 211, "% time spent exploring": 66}
{"steps": 169350, "mean 100 episode reward": 1720.4, "episodes": 212, "% time spent exploring": 66}
{"steps": 169591, "mean 100 episode reward": 1715.4, "episodes": 213, "% time spent exploring": 66}
{"steps": 170718, "mean 100 episode reward": 1715.7, "episodes": 214, "% time spent exploring": 65}
{"steps": 171273, "mean 100 episode reward": 1715.2, "episodes": 215, "% time spent exploring": 65}
{"steps": 172158, "mean 100 episode reward": 1720.0, "episodes": 216, "% time spent exploring": 65}
{"steps": 173116, "mean 100 episode reward": 1726.4, "episodes": 217, "% time spent exploring": 65}
{"steps": 173772, "mean 100 episode reward": 1731.3, "episodes": 218, "% time spent exploring": 65}
{"steps": 174011, "mean 100 episode reward": 1727.3, "episodes": 219, "% time spent exploring": 65}
{"steps": 174754, "mean 100 episode reward": 1719.8, "episodes": 220, "% time spent exploring": 65}
{"steps": 175497, "mean 100 episode reward": 1726.5, "episodes": 221, "% time spent exploring": 64}
{"steps": 176075, "mean 100 episode reward": 1714.1, "episodes": 222, "% time spent exploring": 64}
{"steps": 176636, "mean 100 episode reward": 1717.8, "episodes": 223, "% time spent exploring": 64}
{"steps": 176887, "mean 100 episode reward": 1711.6, "episodes": 224, "% time spent exploring": 64}
{"steps": 177182, "mean 100 episode reward": 1708.8, "episodes": 225, "% time spent exploring": 64}
{"steps": 177782, "mean 100 episode reward": 1707.8, "episodes": 226, "% time spent exploring": 64}
{"steps": 178414, "mean 100 episode reward": 1708.6, "episodes": 227, "% time spent exploring": 64}
{"steps": 179422, "mean 100 episode reward": 1709.5, "episodes": 228, "% time spent exploring": 64}
{"steps": 179837, "mean 100 episode reward": 1700.3, "episodes": 229, "% time spent exploring": 64}
{"steps": 180404, "mean 100 episode reward": 1703.3, "episodes": 230, "% time spent exploring": 63}
{"steps": 181827, "mean 100 episode reward": 1708.4, "episodes": 231, "% time spent exploring": 63}
{"steps": 182233, "mean 100 episode reward": 1711.8, "episodes": 232, "% time spent exploring": 63}
{"steps": 183184, "mean 100 episode reward": 1715.9, "episodes": 233, "% time spent exploring": 63}
{"steps": 183576, "mean 100 episode reward": 1719.8, "episodes": 234, "% time spent exploring": 63}
{"steps": 184246, "mean 100 episode reward": 1728.0, "episodes": 235, "% time spent exploring": 63}
{"steps": 185079, "mean 100 episode reward": 1727.7, "episodes": 236, "% time spent exploring": 62}
{"steps": 185367, "mean 100 episode reward": 1730.5, "episodes": 237, "% time spent exploring": 62}
{"steps": 185825, "mean 100 episode reward": 1728.7, "episodes": 238, "% time spent exploring": 62}
{"steps": 186105, "mean 100 episode reward": 1717.5, "episodes": 239, "% time spent exploring": 62}
{"steps": 187246, "mean 100 episode reward": 1722.2, "episodes": 240, "% time spent exploring": 62}
{"steps": 188199, "mean 100 episode reward": 1731.4, "episodes": 241, "% time spent exploring": 62}
{"steps": 190233, "mean 100 episode reward": 1739.2, "episodes": 242, "% time spent exploring": 61}
{"steps": 190863, "mean 100 episode reward": 1745.2, "episodes": 243, "% time spent exploring": 61}
{"steps": 192198, "mean 100 episode reward": 1745.2, "episodes": 244, "% time spent exploring": 61}
{"steps": 192929, "mean 100 episode reward": 1738.6, "episodes": 245, "% time spent exploring": 61}
{"steps": 193955, "mean 100 episode reward": 1750.8, "episodes": 246, "% time spent exploring": 61}
{"steps": 194624, "mean 100 episode reward": 1752.0, "episodes": 247, "% time spent exploring": 61}
{"steps": 195308, "mean 100 episode reward": 1759.0, "episodes": 248, "% time spent exploring": 60}
{"steps": 195475, "mean 100 episode reward": 1750.8, "episodes": 249, "% time spent exploring": 60}
{"steps": 195847, "mean 100 episode reward": 1746.1, "episodes": 250, "% time spent exploring": 60}
{"steps": 196338, "mean 100 episode reward": 1751.8, "episodes": 251, "% time spent exploring": 60}
{"steps": 196636, "mean 100 episode reward": 1760.0, "episodes": 252, "% time spent exploring": 60}
{"steps": 196946, "mean 100 episode reward": 1763.4, "episodes": 253, "% time spent exploring": 60}
{"steps": 197090, "mean 100 episode reward": 1758.1, "episodes": 254, "% time spent exploring": 60}
{"steps": 197478, "mean 100 episode reward": 1765.1, "episodes": 255, "% time spent exploring": 60}
{"steps": 198070, "mean 100 episode reward": 1760.0, "episodes": 256, "% time spent exploring": 60}
{"steps": 198522, "mean 100 episode reward": 1767.3, "episodes": 257, "% time spent exploring": 60}
{"steps": 199089, "mean 100 episode reward": 1780.6, "episodes": 258, "% time spent exploring": 60}
{"steps": 199416, "mean 100 episode reward": 1773.1, "episodes": 259, "% time spent exploring": 60}
{"steps": 200188, "mean 100 episode reward": 1780.1, "episodes": 260, "% time spent exploring": 59}
{"steps": 200518, "mean 100 episode reward": 1782.7, "episodes": 261, "% time spent exploring": 59}
{"steps": 201080, "mean 100 episode reward": 1784.4, "episodes": 262, "% time spent exploring": 59}
{"steps": 201793, "mean 100 episode reward": 1784.5, "episodes": 263, "% time spent exploring": 59}
{"steps": 202127, "mean 100 episode reward": 1780.4, "episodes": 264, "% time spent exploring": 59}
{"steps": 202623, "mean 100 episode reward": 1789.0, "episodes": 265, "% time spent exploring": 59}
{"steps": 202960, "mean 100 episode reward": 1788.4, "episodes": 266, "% time spent exploring": 59}
{"steps": 204089, "mean 100 episode reward": 1800.8, "episodes": 267, "% time spent exploring": 59}
{"steps": 204469, "mean 100 episode reward": 1805.5, "episodes": 268, "% time spent exploring": 59}
{"steps": 205089, "mean 100 episode reward": 1796.1, "episodes": 269, "% time spent exploring": 58}
{"steps": 205521, "mean 100 episode reward": 1797.3, "episodes": 270, "% time spent exploring": 58}
{"steps": 205978, "mean 100 episode reward": 1796.8, "episodes": 271, "% time spent exploring": 58}
{"steps": 206650, "mean 100 episode reward": 1790.1, "episodes": 272, "% time spent exploring": 58}
{"steps": 206932, "mean 100 episode reward": 1793.0, "episodes": 273, "% time spent exploring": 58}
{"steps": 207444, "mean 100 episode reward": 1800.7, "episodes": 274, "% time spent exploring": 58}
{"steps": 207827, "mean 100 episode reward": 1808.0, "episodes": 275, "% time spent exploring": 58}
{"steps": 208016, "mean 100 episode reward": 1789.0, "episodes": 276, "% time spent exploring": 58}
{"steps": 208901, "mean 100 episode reward": 1795.8, "episodes": 277, "% time spent exploring": 58}
{"steps": 209225, "mean 100 episode reward": 1794.0, "episodes": 278, "% time spent exploring": 58}
{"steps": 209835, "mean 100 episode reward": 1809.0, "episodes": 279, "% time spent exploring": 58}
{"steps": 211046, "mean 100 episode reward": 1798.4, "episodes": 280, "% time spent exploring": 57}
{"steps": 211239, "mean 100 episode reward": 1794.8, "episodes": 281, "% time spent exploring": 57}
{"steps": 211691, "mean 100 episode reward": 1797.0, "episodes": 282, "% time spent exploring": 57}
{"steps": 212479, "mean 100 episode reward": 1804.4, "episodes": 283, "% time spent exploring": 57}
{"steps": 213382, "mean 100 episode reward": 1798.2, "episodes": 284, "% time spent exploring": 57}
{"steps": 214276, "mean 100 episode reward": 1810.1, "episodes": 285, "% time spent exploring": 57}
{"steps": 214968, "mean 100 episode reward": 1818.6, "episodes": 286, "% time spent exploring": 57}
{"steps": 215618, "mean 100 episode reward": 1821.1, "episodes": 287, "% time spent exploring": 56}
{"steps": 216114, "mean 100 episode reward": 1826.2, "episodes": 288, "% time spent exploring": 56}
{"steps": 216413, "mean 100 episode reward": 1817.8, "episodes": 289, "% time spent exploring": 56}
{"steps": 216633, "mean 100 episode reward": 1807.0, "episodes": 290, "% time spent exploring": 56}
{"steps": 217567, "mean 100 episode reward": 1811.9, "episodes": 291, "% time spent exploring": 56}
{"steps": 219912, "mean 100 episode reward": 1816.8, "episodes": 292, "% time spent exploring": 56}
{"steps": 220260, "mean 100 episode reward": 1817.7, "episodes": 293, "% time spent exploring": 55}
{"steps": 220886, "mean 100 episode reward": 1822.8, "episodes": 294, "% time spent exploring": 55}
{"steps": 221442, "mean 100 episode reward": 1829.3, "episodes": 295, "% time spent exploring": 55}
{"steps": 221834, "mean 100 episode reward": 1826.3, "episodes": 296, "% time spent exploring": 55}
{"steps": 222762, "mean 100 episode reward": 1829.6, "episodes": 297, "% time spent exploring": 55}
{"steps": 223239, "mean 100 episode reward": 1830.6, "episodes": 298, "% time spent exploring": 55}
{"steps": 223824, "mean 100 episode reward": 1839.6, "episodes": 299, "% time spent exploring": 55}
{"steps": 224089, "mean 100 episode reward": 1840.2, "episodes": 300, "% time spent exploring": 55}
{"steps": 224337, "mean 100 episode reward": 1843.8, "episodes": 301, "% time spent exploring": 55}
{"steps": 224820, "mean 100 episode reward": 1838.8, "episodes": 302, "% time spent exploring": 55}
{"steps": 225326, "mean 100 episode reward": 1839.6, "episodes": 303, "% time spent exploring": 54}
{"steps": 225750, "mean 100 episode reward": 1837.0, "episodes": 304, "% time spent exploring": 54}
{"steps": 226067, "mean 100 episode reward": 1841.6, "episodes": 305, "% time spent exploring": 54}
{"steps": 226943, "mean 100 episode reward": 1859.2, "episodes": 306, "% time spent exploring": 54}
{"steps": 227718, "mean 100 episode reward": 1860.0, "episodes": 307, "% time spent exploring": 54}
{"steps": 228357, "mean 100 episode reward": 1873.3, "episodes": 308, "% time spent exploring": 54}
{"steps": 228753, "mean 100 episode reward": 1865.1, "episodes": 309, "% time spent exploring": 54}
{"steps": 229171, "mean 100 episode reward": 1856.3, "episodes": 310, "% time spent exploring": 54}
{"steps": 229501, "mean 100 episode reward": 1848.6, "episodes": 311, "% time spent exploring": 54}
{"steps": 229945, "mean 100 episode reward": 1855.7, "episodes": 312, "% time spent exploring": 54}
{"steps": 230375, "mean 100 episode reward": 1856.2, "episodes": 313, "% time spent exploring": 53}
{"steps": 230614, "mean 100 episode reward": 1844.1, "episodes": 314, "% time spent exploring": 53}
{"steps": 230872, "mean 100 episode reward": 1840.1, "episodes": 315, "% time spent exploring": 53}
{"steps": 231571, "mean 100 episode reward": 1852.7, "episodes": 316, "% time spent exploring": 53}
{"steps": 232292, "mean 100 episode reward": 1857.3, "episodes": 317, "% time spent exploring": 53}
{"steps": 232807, "mean 100 episode reward": 1853.7, "episodes": 318, "% time spent exploring": 53}
{"steps": 233197, "mean 100 episode reward": 1862.4, "episodes": 319, "% time spent exploring": 53}
{"steps": 233495, "mean 100 episode reward": 1855.1, "episodes": 320, "% time spent exploring": 53}
{"steps": 234090, "mean 100 episode reward": 1857.3, "episodes": 321, "% time spent exploring": 53}
{"steps": 234431, "mean 100 episode reward": 1862.0, "episodes": 322, "% time spent exploring": 53}
{"steps": 234789, "mean 100 episode reward": 1861.3, "episodes": 323, "% time spent exploring": 53}
{"steps": 235101, "mean 100 episode reward": 1861.8, "episodes": 324, "% time spent exploring": 52}
{"steps": 235464, "mean 100 episode reward": 1864.9, "episodes": 325, "% time spent exploring": 52}
{"steps": 235926, "mean 100 episode reward": 1871.1, "episodes": 326, "% time spent exploring": 52}
{"steps": 236381, "mean 100 episode reward": 1864.6, "episodes": 327, "% time spent exploring": 52}
{"steps": 236800, "mean 100 episode reward": 1861.5, "episodes": 328, "% time spent exploring": 52}
{"steps": 237196, "mean 100 episode reward": 1860.5, "episodes": 329, "% time spent exploring": 52}
{"steps": 237885, "mean 100 episode reward": 1864.4, "episodes": 330, "% time spent exploring": 52}
{"steps": 238189, "mean 100 episode reward": 1855.5, "episodes": 331, "% time spent exploring": 52}
{"steps": 238567, "mean 100 episode reward": 1860.7, "episodes": 332, "% time spent exploring": 52}
{"steps": 238822, "mean 100 episode reward": 1854.5, "episodes": 333, "% time spent exploring": 52}
{"steps": 239151, "mean 100 episode reward": 1856.3, "episodes": 334, "% time spent exploring": 52}
{"steps": 239641, "mean 100 episode reward": 1851.7, "episodes": 335, "% time spent exploring": 52}
{"steps": 240559, "mean 100 episode reward": 1864.4, "episodes": 336, "% time spent exploring": 51}
{"steps": 240709, "mean 100 episode reward": 1856.6, "episodes": 337, "% time spent exploring": 51}
{"steps": 241232, "mean 100 episode reward": 1856.2, "episodes": 338, "% time spent exploring": 51}
{"steps": 241733, "mean 100 episode reward": 1864.5, "episodes": 339, "% time spent exploring": 51}
{"steps": 242422, "mean 100 episode reward": 1872.1, "episodes": 340, "% time spent exploring": 51}
{"steps": 242808, "mean 100 episode reward": 1864.3, "episodes": 341, "% time spent exploring": 51}
{"steps": 243083, "mean 100 episode reward": 1862.0, "episodes": 342, "% time spent exploring": 51}
{"steps": 243395, "mean 100 episode reward": 1855.2, "episodes": 343, "% time spent exploring": 51}
{"steps": 243911, "mean 100 episode reward": 1861.6, "episodes": 344, "% time spent exploring": 51}
{"steps": 244456, "mean 100 episode reward": 1871.6, "episodes": 345, "% time spent exploring": 51}
{"steps": 244810, "mean 100 episode reward": 1859.4, "episodes": 346, "% time spent exploring": 51}
{"steps": 245492, "mean 100 episode reward": 1865.0, "episodes": 347, "% time spent exploring": 50}
{"steps": 245684, "mean 100 episode reward": 1854.3, "episodes": 348, "% time spent exploring": 50}
{"steps": 246297, "mean 100 episode reward": 1855.3, "episodes": 349, "% time spent exploring": 50}
{"steps": 246470, "mean 100 episode reward": 1849.0, "episodes": 350, "% time spent exploring": 50}
{"steps": 246805, "mean 100 episode reward": 1842.6, "episodes": 351, "% time spent exploring": 50}
{"steps": 247234, "mean 100 episode reward": 1844.4, "episodes": 352, "% time spent exploring": 50}
{"steps": 247537, "mean 100 episode reward": 1846.0, "episodes": 353, "% time spent exploring": 50}
{"steps": 247859, "mean 100 episode reward": 1852.2, "episodes": 354, "% time spent exploring": 50}
{"steps": 248100, "mean 100 episode reward": 1852.7, "episodes": 355, "% time spent exploring": 50}
{"steps": 248294, "mean 100 episode reward": 1845.3, "episodes": 356, "% time spent exploring": 50}
{"steps": 248887, "mean 100 episode reward": 1848.9, "episodes": 357, "% time spent exploring": 50}
{"steps": 249146, "mean 100 episode reward": 1838.5, "episodes": 358, "% time spent exploring": 50}
{"steps": 249443, "mean 100 episode reward": 1843.0, "episodes": 359, "% time spent exploring": 50}
{"steps": 249784, "mean 100 episode reward": 1843.9, "episodes": 360, "% time spent exploring": 50}
{"steps": 250205, "mean 100 episode reward": 1849.8, "episodes": 361, "% time spent exploring": 49}
{"steps": 250584, "mean 100 episode reward": 1852.6, "episodes": 362, "% time spent exploring": 49}
{"steps": 250921, "mean 100 episode reward": 1852.3, "episodes": 363, "% time spent exploring": 49}
{"steps": 251182, "mean 100 episode reward": 1849.1, "episodes": 364, "% time spent exploring": 49}
{"steps": 251412, "mean 100 episode reward": 1842.9, "episodes": 365, "% time spent exploring": 49}
{"steps": 252283, "mean 100 episode reward": 1850.8, "episodes": 366, "% time spent exploring": 49}
{"steps": 252647, "mean 100 episode reward": 1835.7, "episodes": 367, "% time spent exploring": 49}
{"steps": 252975, "mean 100 episode reward": 1835.6, "episodes": 368, "% time spent exploring": 49}
{"steps": 253302, "mean 100 episode reward": 1839.7, "episodes": 369, "% time spent exploring": 49}
{"steps": 253537, "mean 100 episode reward": 1838.4, "episodes": 370, "% time spent exploring": 49}
{"steps": 253899, "mean 100 episode reward": 1840.3, "episodes": 371, "% time spent exploring": 49}
{"steps": 254275, "mean 100 episode reward": 1842.8, "episodes": 372, "% time spent exploring": 49}
{"steps": 254558, "mean 100 episode reward": 1844.1, "episodes": 373, "% time spent exploring": 49}
{"steps": 255121, "mean 100 episode reward": 1853.1, "episodes": 374, "% time spent exploring": 48}
{"steps": 255662, "mean 100 episode reward": 1857.6, "episodes": 375, "% time spent exploring": 48}
{"steps": 256201, "mean 100 episode reward": 1877.0, "episodes": 376, "% time spent exploring": 48}
{"steps": 256533, "mean 100 episode reward": 1867.9, "episodes": 377, "% time spent exploring": 48}
{"steps": 256903, "mean 100 episode reward": 1868.2, "episodes": 378, "% time spent exploring": 48}
{"steps": 257163, "mean 100 episode reward": 1862.8, "episodes": 379, "% time spent exploring": 48}
{"steps": 258343, "mean 100 episode reward": 1866.9, "episodes": 380, "% time spent exploring": 48}
{"steps": 258752, "mean 100 episode reward": 1879.0, "episodes": 381, "% time spent exploring": 48}
{"steps": 259294, "mean 100 episode reward": 1885.8, "episodes": 382, "% time spent exploring": 48}
{"steps": 259793, "mean 100 episode reward": 1887.8, "episodes": 383, "% time spent exploring": 48}
{"steps": 260135, "mean 100 episode reward": 1887.3, "episodes": 384, "% time spent exploring": 47}
{"steps": 260754, "mean 100 episode reward": 1886.5, "episodes": 385, "% time spent exploring": 47}
{"steps": 261103, "mean 100 episode reward": 1872.7, "episodes": 386, "% time spent exploring": 47}
{"steps": 261690, "mean 100 episode reward": 1873.8, "episodes": 387, "% time spent exploring": 47}
{"steps": 262163, "mean 100 episode reward": 1876.8, "episodes": 388, "% time spent exploring": 47}
{"steps": 262487, "mean 100 episode reward": 1877.7, "episodes": 389, "% time spent exploring": 47}
{"steps": 262988, "mean 100 episode reward": 1887.1, "episodes": 390, "% time spent exploring": 47}
{"steps": 263258, "mean 100 episode reward": 1877.6, "episodes": 391, "% time spent exploring": 47}
{"steps": 263723, "mean 100 episode reward": 1872.6, "episodes": 392, "% time spent exploring": 47}
{"steps": 264083, "mean 100 episode reward": 1872.9, "episodes": 393, "% time spent exploring": 47}
{"steps": 264445, "mean 100 episode reward": 1860.4, "episodes": 394, "% time spent exploring": 47}
{"steps": 264909, "mean 100 episode reward": 1855.2, "episodes": 395, "% time spent exploring": 47}
{"steps": 265398, "mean 100 episode reward": 1859.8, "episodes": 396, "% time spent exploring": 46}
{"steps": 265734, "mean 100 episode reward": 1863.1, "episodes": 397, "% time spent exploring": 46}
{"steps": 266156, "mean 100 episode reward": 1865.4, "episodes": 398, "% time spent exploring": 46}
{"steps": 266460, "mean 100 episode reward": 1858.0, "episodes": 399, "% time spent exploring": 46}
{"steps": 266981, "mean 100 episode reward": 1876.6, "episodes": 400, "% time spent exploring": 46}
{"steps": 267609, "mean 100 episode reward": 1890.0, "episodes": 401, "% time spent exploring": 46}
{"steps": 267712, "mean 100 episode reward": 1878.3, "episodes": 402, "% time spent exploring": 46}
{"steps": 267975, "mean 100 episode reward": 1876.2, "episodes": 403, "% time spent exploring": 46}
{"steps": 268474, "mean 100 episode reward": 1876.7, "episodes": 404, "% time spent exploring": 46}
{"steps": 268927, "mean 100 episode reward": 1875.9, "episodes": 405, "% time spent exploring": 46}
{"steps": 269439, "mean 100 episode reward": 1863.6, "episodes": 406, "% time spent exploring": 46}
{"steps": 269685, "mean 100 episode reward": 1854.0, "episodes": 407, "% time spent exploring": 46}
{"steps": 270149, "mean 100 episode reward": 1851.5, "episodes": 408, "% time spent exploring": 45}
{"steps": 270442, "mean 100 episode reward": 1853.1, "episodes": 409, "% time spent exploring": 45}
{"steps": 270894, "mean 100 episode reward": 1863.1, "episodes": 410, "% time spent exploring": 45}
{"steps": 271529, "mean 100 episode reward": 1871.4, "episodes": 411, "% time spent exploring": 45}
{"steps": 272024, "mean 100 episode reward": 1876.6, "episodes": 412, "% time spent exploring": 45}
{"steps": 272395, "mean 100 episode reward": 1884.2, "episodes": 413, "% time spent exploring": 45}
{"steps": 272613, "mean 100 episode reward": 1886.7, "episodes": 414, "% time spent exploring": 45}
{"steps": 272957, "mean 100 episode reward": 1896.4, "episodes": 415, "% time spent exploring": 45}
{"steps": 273555, "mean 100 episode reward": 1887.1, "episodes": 416, "% time spent exploring": 45}
{"steps": 273842, "mean 100 episode reward": 1882.6, "episodes": 417, "% time spent exploring": 45}
{"steps": 274230, "mean 100 episode reward": 1884.9, "episodes": 418, "% time spent exploring": 45}
{"steps": 274707, "mean 100 episode reward": 1881.5, "episodes": 419, "% time spent exploring": 45}
{"steps": 275444, "mean 100 episode reward": 1901.4, "episodes": 420, "% time spent exploring": 44}
{"steps": 275857, "mean 100 episode reward": 1897.6, "episodes": 421, "% time spent exploring": 44}
{"steps": 276397, "mean 100 episode reward": 1906.1, "episodes": 422, "% time spent exploring": 44}
{"steps": 276788, "mean 100 episode reward": 1907.6, "episodes": 423, "% time spent exploring": 44}
{"steps": 277229, "mean 100 episode reward": 1906.2, "episodes": 424, "% time spent exploring": 44}
{"steps": 277494, "mean 100 episode reward": 1897.3, "episodes": 425, "% time spent exploring": 44}
{"steps": 277862, "mean 100 episode reward": 1893.5, "episodes": 426, "% time spent exploring": 44}
{"steps": 278360, "mean 100 episode reward": 1898.7, "episodes": 427, "% time spent exploring": 44}
{"steps": 278462, "mean 100 episode reward": 1884.5, "episodes": 428, "% time spent exploring": 44}
{"steps": 278803, "mean 100 episode reward": 1892.9, "episodes": 429, "% time spent exploring": 44}
{"steps": 279040, "mean 100 episode reward": 1882.3, "episodes": 430, "% time spent exploring": 44}
{"steps": 279274, "mean 100 episode reward": 1883.0, "episodes": 431, "% time spent exploring": 44}
{"steps": 279785, "mean 100 episode reward": 1885.2, "episodes": 432, "% time spent exploring": 44}
{"steps": 280234, "mean 100 episode reward": 1893.7, "episodes": 433, "% time spent exploring": 43}
{"steps": 280460, "mean 100 episode reward": 1891.8, "episodes": 434, "% time spent exploring": 43}
{"steps": 280975, "mean 100 episode reward": 1893.3, "episodes": 435, "% time spent exploring": 43}
{"steps": 281579, "mean 100 episode reward": 1889.1, "episodes": 436, "% time spent exploring": 43}
{"steps": 282022, "mean 100 episode reward": 1898.7, "episodes": 437, "% time spent exploring": 43}
{"steps": 282594, "mean 100 episode reward": 1903.3, "episodes": 438, "% time spent exploring": 43}
{"steps": 282716, "mean 100 episode reward": 1886.2, "episodes": 439, "% time spent exploring": 43}
{"steps": 283026, "mean 100 episode reward": 1876.9, "episodes": 440, "% time spent exploring": 43}
{"steps": 283675, "mean 100 episode reward": 1896.5, "episodes": 441, "% time spent exploring": 43}
{"steps": 284216, "mean 100 episode reward": 1897.4, "episodes": 442, "% time spent exploring": 43}
{"steps": 284603, "mean 100 episode reward": 1905.8, "episodes": 443, "% time spent exploring": 43}
{"steps": 284892, "mean 100 episode reward": 1905.7, "episodes": 444, "% time spent exploring": 43}
{"steps": 285058, "mean 100 episode reward": 1890.3, "episodes": 445, "% time spent exploring": 42}
{"steps": 285418, "mean 100 episode reward": 1886.6, "episodes": 446, "% time spent exploring": 42}
{"steps": 285857, "mean 100 episode reward": 1890.0, "episodes": 447, "% time spent exploring": 42}
{"steps": 286291, "mean 100 episode reward": 1900.7, "episodes": 448, "% time spent exploring": 42}
{"steps": 286676, "mean 100 episode reward": 1907.5, "episodes": 449, "% time spent exploring": 42}
{"steps": 286867, "mean 100 episode reward": 1909.1, "episodes": 450, "% time spent exploring": 42}
{"steps": 287216, "mean 100 episode reward": 1920.3, "episodes": 451, "% time spent exploring": 42}
{"steps": 287637, "mean 100 episode reward": 1919.8, "episodes": 452, "% time spent exploring": 42}
{"steps": 287952, "mean 100 episode reward": 1922.0, "episodes": 453, "% time spent exploring": 42}
{"steps": 288410, "mean 100 episode reward": 1926.1, "episodes": 454, "% time spent exploring": 42}
{"steps": 288621, "mean 100 episode reward": 1926.4, "episodes": 455, "% time spent exploring": 42}
{"steps": 288863, "mean 100 episode reward": 1931.4, "episodes": 456, "% time spent exploring": 42}
{"steps": 289147, "mean 100 episode reward": 1926.3, "episodes": 457, "% time spent exploring": 42}
{"steps": 289297, "mean 100 episode reward": 1922.3, "episodes": 458, "% time spent exploring": 42}
{"steps": 289631, "mean 100 episode reward": 1923.7, "episodes": 459, "% time spent exploring": 42}
{"steps": 289922, "mean 100 episode reward": 1918.6, "episodes": 460, "% time spent exploring": 42}
{"steps": 290327, "mean 100 episode reward": 1920.2, "episodes": 461, "% time spent exploring": 41}
{"steps": 290882, "mean 100 episode reward": 1924.4, "episodes": 462, "% time spent exploring": 41}
{"steps": 291199, "mean 100 episode reward": 1922.8, "episodes": 463, "% time spent exploring": 41}
{"steps": 291655, "mean 100 episode reward": 1924.4, "episodes": 464, "% time spent exploring": 41}
{"steps": 292033, "mean 100 episode reward": 1933.6, "episodes": 465, "% time spent exploring": 41}
{"steps": 292140, "mean 100 episode reward": 1917.3, "episodes": 466, "% time spent exploring": 41}
{"steps": 292368, "mean 100 episode reward": 1912.2, "episodes": 467, "% time spent exploring": 41}
{"steps": 292915, "mean 100 episode reward": 1923.7, "episodes": 468, "% time spent exploring": 41}
{"steps": 293419, "mean 100 episode reward": 1936.8, "episodes": 469, "% time spent exploring": 41}
{"steps": 293819, "mean 100 episode reward": 1940.5, "episodes": 470, "% time spent exploring": 41}
{"steps": 294189, "mean 100 episode reward": 1947.0, "episodes": 471, "% time spent exploring": 41}
{"steps": 294443, "mean 100 episode reward": 1946.0, "episodes": 472, "% time spent exploring": 41}
{"steps": 294616, "mean 100 episode reward": 1941.5, "episodes": 473, "% time spent exploring": 41}
{"steps": 295097, "mean 100 episode reward": 1947.6, "episodes": 474, "% time spent exploring": 40}
{"steps": 295300, "mean 100 episode reward": 1939.9, "episodes": 475, "% time spent exploring": 40}
{"steps": 295635, "mean 100 episode reward": 1932.3, "episodes": 476, "% time spent exploring": 40}
{"steps": 295916, "mean 100 episode reward": 1924.7, "episodes": 477, "% time spent exploring": 40}
{"steps": 296120, "mean 100 episode reward": 1918.4, "episodes": 478, "% time spent exploring": 40}
{"steps": 296405, "mean 100 episode reward": 1914.5, "episodes": 479, "% time spent exploring": 40}
{"steps": 296710, "mean 100 episode reward": 1909.4, "episodes": 480, "% time spent exploring": 40}
{"steps": 297011, "mean 100 episode reward": 1899.6, "episodes": 481, "% time spent exploring": 40}
{"steps": 297604, "mean 100 episode reward": 1902.8, "episodes": 482, "% time spent exploring": 40}
{"steps": 298011, "mean 100 episode reward": 1904.3, "episodes": 483, "% time spent exploring": 40}
{"steps": 298370, "mean 100 episode reward": 1910.0, "episodes": 484, "% time spent exploring": 40}
{"steps": 298723, "mean 100 episode reward": 1904.4, "episodes": 485, "% time spent exploring": 40}
{"steps": 298949, "mean 100 episode reward": 1905.0, "episodes": 486, "% time spent exploring": 40}
{"steps": 299129, "mean 100 episode reward": 1892.1, "episodes": 487, "% time spent exploring": 40}
{"steps": 299429, "mean 100 episode reward": 1886.5, "episodes": 488, "% time spent exploring": 40}
{"steps": 300079, "mean 100 episode reward": 1899.6, "episodes": 489, "% time spent exploring": 39}
{"steps": 300493, "mean 100 episode reward": 1904.2, "episodes": 490, "% time spent exploring": 39}
{"steps": 300841, "mean 100 episode reward": 1913.3, "episodes": 491, "% time spent exploring": 39}
{"steps": 300947, "mean 100 episode reward": 1902.6, "episodes": 492, "% time spent exploring": 39}
{"steps": 301409, "mean 100 episode reward": 1907.8, "episodes": 493, "% time spent exploring": 39}
{"steps": 301775, "mean 100 episode reward": 1911.5, "episodes": 494, "% time spent exploring": 39}
{"steps": 302121, "mean 100 episode reward": 1915.5, "episodes": 495, "% time spent exploring": 39}
{"steps": 302297, "mean 100 episode reward": 1907.1, "episodes": 496, "% time spent exploring": 39}
{"steps": 302877, "mean 100 episode reward": 1914.3, "episodes": 497, "% time spent exploring": 39}
{"steps": 303118, "mean 100 episode reward": 1906.1, "episodes": 498, "% time spent exploring": 39}
{"steps": 303545, "mean 100 episode reward": 1906.0, "episodes": 499, "% time spent exploring": 39}
{"steps": 304181, "mean 100 episode reward": 1903.6, "episodes": 500, "% time spent exploring": 39}
{"steps": 304398, "mean 100 episode reward": 1890.1, "episodes": 501, "% time spent exploring": 39}
{"steps": 304803, "mean 100 episode reward": 1904.0, "episodes": 502, "% time spent exploring": 39}
{"steps": 305199, "mean 100 episode reward": 1907.6, "episodes": 503, "% time spent exploring": 38}
{"steps": 305657, "mean 100 episode reward": 1910.0, "episodes": 504, "% time spent exploring": 38}
{"steps": 305855, "mean 100 episode reward": 1906.6, "episodes": 505, "% time spent exploring": 38}
{"steps": 307123, "mean 100 episode reward": 1911.7, "episodes": 506, "% time spent exploring": 38}
{"steps": 307355, "mean 100 episode reward": 1911.1, "episodes": 507, "% time spent exploring": 38}
{"steps": 307739, "mean 100 episode reward": 1903.7, "episodes": 508, "% time spent exploring": 38}
{"steps": 308056, "mean 100 episode reward": 1903.4, "episodes": 509, "% time spent exploring": 38}
{"steps": 308504, "mean 100 episode reward": 1898.6, "episodes": 510, "% time spent exploring": 38}
{"steps": 308842, "mean 100 episode reward": 1895.6, "episodes": 511, "% time spent exploring": 38}
{"steps": 309122, "mean 100 episode reward": 1890.9, "episodes": 512, "% time spent exploring": 38}
{"steps": 309486, "mean 100 episode reward": 1882.7, "episodes": 513, "% time spent exploring": 38}
{"steps": 309717, "mean 100 episode reward": 1879.2, "episodes": 514, "% time spent exploring": 38}
{"steps": 309914, "mean 100 episode reward": 1870.0, "episodes": 515, "% time spent exploring": 38}
{"steps": 310241, "mean 100 episode reward": 1858.8, "episodes": 516, "% time spent exploring": 37}
{"steps": 310589, "mean 100 episode reward": 1857.2, "episodes": 517, "% time spent exploring": 37}
{"steps": 311484, "mean 100 episode reward": 1856.2, "episodes": 518, "% time spent exploring": 37}
{"steps": 312233, "mean 100 episode reward": 1882.6, "episodes": 519, "% time spent exploring": 37}
{"steps": 312708, "mean 100 episode reward": 1874.9, "episodes": 520, "% time spent exploring": 37}
{"steps": 312917, "mean 100 episode reward": 1866.7, "episodes": 521, "% time spent exploring": 37}
{"steps": 313108, "mean 100 episode reward": 1850.3, "episodes": 522, "% time spent exploring": 37}
{"steps": 313548, "mean 100 episode reward": 1852.9, "episodes": 523, "% time spent exploring": 37}
{"steps": 313995, "mean 100 episode reward": 1855.3, "episodes": 524, "% time spent exploring": 37}
{"steps": 314304, "mean 100 episode reward": 1862.7, "episodes": 525, "% time spent exploring": 37}
{"steps": 314428, "mean 100 episode reward": 1853.3, "episodes": 526, "% time spent exploring": 37}
{"steps": 314759, "mean 100 episode reward": 1852.0, "episodes": 527, "% time spent exploring": 37}
{"steps": 315231, "mean 100 episode reward": 1866.0, "episodes": 528, "% time spent exploring": 36}
{"steps": 315545, "mean 100 episode reward": 1861.4, "episodes": 529, "% time spent exploring": 36}
{"steps": 316142, "mean 100 episode reward": 1873.5, "episodes": 530, "% time spent exploring": 36}
{"steps": 316622, "mean 100 episode reward": 1882.6, "episodes": 531, "% time spent exploring": 36}
{"steps": 317224, "mean 100 episode reward": 1894.5, "episodes": 532, "% time spent exploring": 36}
{"steps": 317698, "mean 100 episode reward": 1901.6, "episodes": 533, "% time spent exploring": 36}
{"steps": 317915, "mean 100 episode reward": 1901.1, "episodes": 534, "% time spent exploring": 36}
{"steps": 318259, "mean 100 episode reward": 1891.7, "episodes": 535, "% time spent exploring": 36}
{"steps": 318425, "mean 100 episode reward": 1874.7, "episodes": 536, "% time spent exploring": 36}
{"steps": 318574, "mean 100 episode reward": 1868.8, "episodes": 537, "% time spent exploring": 36}
{"steps": 319098, "mean 100 episode reward": 1868.2, "episodes": 538, "% time spent exploring": 36}
{"steps": 319454, "mean 100 episode reward": 1880.8, "episodes": 539, "% time spent exploring": 36}
{"steps": 319843, "mean 100 episode reward": 1879.4, "episodes": 540, "% time spent exploring": 36}
{"steps": 320065, "mean 100 episode reward": 1855.6, "episodes": 541, "% time spent exploring": 35}
{"steps": 320369, "mean 100 episode reward": 1846.4, "episodes": 542, "% time spent exploring": 35}
{"steps": 320518, "mean 100 episode reward": 1834.9, "episodes": 543, "% time spent exploring": 35}
{"steps": 320805, "mean 100 episode reward": 1832.7, "episodes": 544, "% time spent exploring": 35}
{"steps": 321024, "mean 100 episode reward": 1833.9, "episodes": 545, "% time spent exploring": 35}
{"steps": 321174, "mean 100 episode reward": 1830.3, "episodes": 546, "% time spent exploring": 35}
{"steps": 321382, "mean 100 episode reward": 1817.8, "episodes": 547, "% time spent exploring": 35}
{"steps": 321638, "mean 100 episode reward": 1815.1, "episodes": 548, "% time spent exploring": 35}
{"steps": 322060, "mean 100 episode reward": 1817.7, "episodes": 549, "% time spent exploring": 35}
{"steps": 322511, "mean 100 episode reward": 1821.7, "episodes": 550, "% time spent exploring": 35}
{"steps": 322828, "mean 100 episode reward": 1814.2, "episodes": 551, "% time spent exploring": 35}
{"steps": 323070, "mean 100 episode reward": 1809.3, "episodes": 552, "% time spent exploring": 35}
{"steps": 323304, "mean 100 episode reward": 1805.1, "episodes": 553, "% time spent exploring": 35}
{"steps": 323569, "mean 100 episode reward": 1801.3, "episodes": 554, "% time spent exploring": 35}
{"steps": 323871, "mean 100 episode reward": 1804.9, "episodes": 555, "% time spent exploring": 35}
{"steps": 324136, "mean 100 episode reward": 1808.0, "episodes": 556, "% time spent exploring": 35}
{"steps": 324301, "mean 100 episode reward": 1800.1, "episodes": 557, "% time spent exploring": 35}
{"steps": 324423, "mean 100 episode reward": 1800.4, "episodes": 558, "% time spent exploring": 35}
{"steps": 324816, "mean 100 episode reward": 1804.4, "episodes": 559, "% time spent exploring": 35}
{"steps": 325072, "mean 100 episode reward": 1804.6, "episodes": 560, "% time spent exploring": 34}
{"steps": 325316, "mean 100 episode reward": 1794.9, "episodes": 561, "% time spent exploring": 34}
{"steps": 325484, "mean 100 episode reward": 1778.2, "episodes": 562, "% time spent exploring": 34}
{"steps": 325799, "mean 100 episode reward": 1778.8, "episodes": 563, "% time spent exploring": 34}
{"steps": 326227, "mean 100 episode reward": 1782.6, "episodes": 564, "% time spent exploring": 34}
{"steps": 326540, "mean 100 episode reward": 1780.8, "episodes": 565, "% time spent exploring": 34}
{"steps": 326771, "mean 100 episode reward": 1788.0, "episodes": 566, "% time spent exploring": 34}
{"steps": 327260, "mean 100 episode reward": 1803.4, "episodes": 567, "% time spent exploring": 34}
{"steps": 327452, "mean 100 episode reward": 1791.2, "episodes": 568, "% time spent exploring": 34}
{"steps": 327753, "mean 100 episode reward": 1781.4, "episodes": 569, "% time spent exploring": 34}
{"steps": 328082, "mean 100 episode reward": 1777.2, "episodes": 570, "% time spent exploring": 34}
{"steps": 328420, "mean 100 episode reward": 1774.6, "episodes": 571, "% time spent exploring": 34}
{"steps": 328564, "mean 100 episode reward": 1764.4, "episodes": 572, "% time spent exploring": 34}
{"steps": 328878, "mean 100 episode reward": 1773.6, "episodes": 573, "% time spent exploring": 34}
{"steps": 329229, "mean 100 episode reward": 1764.6, "episodes": 574, "% time spent exploring": 34}
{"steps": 329643, "mean 100 episode reward": 1771.1, "episodes": 575, "% time spent exploring": 34}
{"steps": 329854, "mean 100 episode reward": 1767.3, "episodes": 576, "% time spent exploring": 34}
{"steps": 330260, "mean 100 episode reward": 1783.0, "episodes": 577, "% time spent exploring": 33}
{"steps": 330473, "mean 100 episode reward": 1786.0, "episodes": 578, "% time spent exploring": 33}
{"steps": 330659, "mean 100 episode reward": 1780.5, "episodes": 579, "% time spent exploring": 33}
{"steps": 331151, "mean 100 episode reward": 1784.5, "episodes": 580, "% time spent exploring": 33}
{"steps": 331471, "mean 100 episode reward": 1788.3, "episodes": 581, "% time spent exploring": 33}
{"steps": 331714, "mean 100 episode reward": 1776.8, "episodes": 582, "% time spent exploring": 33}
{"steps": 331876, "mean 100 episode reward": 1761.3, "episodes": 583, "% time spent exploring": 33}
{"steps": 332308, "mean 100 episode reward": 1755.9, "episodes": 584, "% time spent exploring": 33}
{"steps": 332676, "mean 100 episode reward": 1757.1, "episodes": 585, "% time spent exploring": 33}
{"steps": 333021, "mean 100 episode reward": 1763.8, "episodes": 586, "% time spent exploring": 33}
{"steps": 333634, "mean 100 episode reward": 1773.3, "episodes": 587, "% time spent exploring": 33}
{"steps": 333825, "mean 100 episode reward": 1770.8, "episodes": 588, "% time spent exploring": 33}
{"steps": 334148, "mean 100 episode reward": 1757.7, "episodes": 589, "% time spent exploring": 33}
{"steps": 334327, "mean 100 episode reward": 1744.0, "episodes": 590, "% time spent exploring": 33}
{"steps": 334713, "mean 100 episode reward": 1743.9, "episodes": 591, "% time spent exploring": 33}
{"steps": 334999, "mean 100 episode reward": 1747.1, "episodes": 592, "% time spent exploring": 33}
{"steps": 335320, "mean 100 episode reward": 1744.2, "episodes": 593, "% time spent exploring": 32}
{"steps": 335564, "mean 100 episode reward": 1742.7, "episodes": 594, "% time spent exploring": 32}
{"steps": 336000, "mean 100 episode reward": 1746.9, "episodes": 595, "% time spent exploring": 32}
{"steps": 336281, "mean 100 episode reward": 1744.8, "episodes": 596, "% time spent exploring": 32}
{"steps": 336523, "mean 100 episode reward": 1729.5, "episodes": 597, "% time spent exploring": 32}
{"steps": 336932, "mean 100 episode reward": 1733.3, "episodes": 598, "% time spent exploring": 32}
{"steps": 337334, "mean 100 episode reward": 1729.8, "episodes": 599, "% time spent exploring": 32}
{"steps": 337520, "mean 100 episode reward": 1717.3, "episodes": 600, "% time spent exploring": 32}
{"steps": 337788, "mean 100 episode reward": 1721.2, "episodes": 601, "% time spent exploring": 32}
{"steps": 338463, "mean 100 episode reward": 1724.1, "episodes": 602, "% time spent exploring": 32}
{"steps": 338949, "mean 100 episode reward": 1737.0, "episodes": 603, "% time spent exploring": 32}
{"steps": 339436, "mean 100 episode reward": 1735.6, "episodes": 604, "% time spent exploring": 32}
{"steps": 339723, "mean 100 episode reward": 1742.8, "episodes": 605, "% time spent exploring": 32}
{"steps": 340074, "mean 100 episode reward": 1739.5, "episodes": 606, "% time spent exploring": 31}
{"steps": 340355, "mean 100 episode reward": 1740.0, "episodes": 607, "% time spent exploring": 31}
{"steps": 340633, "mean 100 episode reward": 1740.5, "episodes": 608, "% time spent exploring": 31}
{"steps": 340971, "mean 100 episode reward": 1747.0, "episodes": 609, "% time spent exploring": 31}
{"steps": 341380, "mean 100 episode reward": 1747.1, "episodes": 610, "% time spent exploring": 31}
{"steps": 341751, "mean 100 episode reward": 1747.8, "episodes": 611, "% time spent exploring": 31}
{"steps": 342260, "mean 100 episode reward": 1749.2, "episodes": 612, "% time spent exploring": 31}
{"steps": 342752, "mean 100 episode reward": 1766.7, "episodes": 613, "% time spent exploring": 31}
{"steps": 343242, "mean 100 episode reward": 1775.5, "episodes": 614, "% time spent exploring": 31}
{"steps": 343531, "mean 100 episode reward": 1777.1, "episodes": 615, "% time spent exploring": 31}
{"steps": 343810, "mean 100 episode reward": 1780.1, "episodes": 616, "% time spent exploring": 31}
{"steps": 343918, "mean 100 episode reward": 1768.8, "episodes": 617, "% time spent exploring": 31}
{"steps": 344188, "mean 100 episode reward": 1763.9, "episodes": 618, "% time spent exploring": 31}
{"steps": 344454, "mean 100 episode reward": 1736.5, "episodes": 619, "% time spent exploring": 31}
{"steps": 344694, "mean 100 episode reward": 1730.7, "episodes": 620, "% time spent exploring": 31}
{"steps": 345066, "mean 100 episode reward": 1746.7, "episodes": 621, "% time spent exploring": 30}
{"steps": 345210, "mean 100 episode reward": 1747.0, "episodes": 622, "% time spent exploring": 30}
{"steps": 345646, "mean 100 episode reward": 1742.5, "episodes": 623, "% time spent exploring": 30}
{"steps": 345894, "mean 100 episode reward": 1741.2, "episodes": 624, "% time spent exploring": 30}
{"steps": 346165, "mean 100 episode reward": 1738.2, "episodes": 625, "% time spent exploring": 30}
{"steps": 346543, "mean 100 episode reward": 1754.4, "episodes": 626, "% time spent exploring": 30}
{"steps": 346694, "mean 100 episode reward": 1746.6, "episodes": 627, "% time spent exploring": 30}
{"steps": 347002, "mean 100 episode reward": 1744.3, "episodes": 628, "% time spent exploring": 30}
{"steps": 347455, "mean 100 episode reward": 1746.5, "episodes": 629, "% time spent exploring": 30}
{"steps": 347673, "mean 100 episode reward": 1731.8, "episodes": 630, "% time spent exploring": 30}
{"steps": 347970, "mean 100 episode reward": 1724.2, "episodes": 631, "% time spent exploring": 30}
{"steps": 348178, "mean 100 episode reward": 1703.8, "episodes": 632, "% time spent exploring": 30}
{"steps": 348411, "mean 100 episode reward": 1690.6, "episodes": 633, "% time spent exploring": 30}
{"steps": 348779, "mean 100 episode reward": 1700.8, "episodes": 634, "% time spent exploring": 30}
{"steps": 349006, "mean 100 episode reward": 1701.2, "episodes": 635, "% time spent exploring": 30}
{"steps": 349364, "mean 100 episode reward": 1707.1, "episodes": 636, "% time spent exploring": 30}
{"steps": 349608, "mean 100 episode reward": 1711.2, "episodes": 637, "% time spent exploring": 30}
{"steps": 349951, "mean 100 episode reward": 1703.9, "episodes": 638, "% time spent exploring": 30}
{"steps": 350503, "mean 100 episode reward": 1711.7, "episodes": 639, "% time spent exploring": 29}
{"steps": 350781, "mean 100 episode reward": 1712.5, "episodes": 640, "% time spent exploring": 29}
{"steps": 350985, "mean 100 episode reward": 1716.4, "episodes": 641, "% time spent exploring": 29}
{"steps": 351273, "mean 100 episode reward": 1720.8, "episodes": 642, "% time spent exploring": 29}
{"steps": 351469, "mean 100 episode reward": 1724.8, "episodes": 643, "% time spent exploring": 29}
{"steps": 351665, "mean 100 episode reward": 1718.0, "episodes": 644, "% time spent exploring": 29}
{"steps": 352001, "mean 100 episode reward": 1724.6, "episodes": 645, "% time spent exploring": 29}
{"steps": 352235, "mean 100 episode reward": 1728.0, "episodes": 646, "% time spent exploring": 29}
{"steps": 352547, "mean 100 episode reward": 1732.8, "episodes": 647, "% time spent exploring": 29}
{"steps": 352874, "mean 100 episode reward": 1735.4, "episodes": 648, "% time spent exploring": 29}
{"steps": 353431, "mean 100 episode reward": 1743.4, "episodes": 649, "% time spent exploring": 29}
{"steps": 353949, "mean 100 episode reward": 1741.5, "episodes": 650, "% time spent exploring": 29}
{"steps": 354379, "mean 100 episode reward": 1746.6, "episodes": 651, "% time spent exploring": 29}
{"steps": 354628, "mean 100 episode reward": 1744.7, "episodes": 652, "% time spent exploring": 29}
{"steps": 354931, "mean 100 episode reward": 1745.9, "episodes": 653, "% time spent exploring": 29}
{"steps": 355328, "mean 100 episode reward": 1747.2, "episodes": 654, "% time spent exploring": 28}
{"steps": 355657, "mean 100 episode reward": 1742.7, "episodes": 655, "% time spent exploring": 28}
{"steps": 356089, "mean 100 episode reward": 1746.3, "episodes": 656, "% time spent exploring": 28}
{"steps": 356521, "mean 100 episode reward": 1750.7, "episodes": 657, "% time spent exploring": 28}
{"steps": 356760, "mean 100 episode reward": 1750.4, "episodes": 658, "% time spent exploring": 28}
{"steps": 357014, "mean 100 episode reward": 1743.1, "episodes": 659, "% time spent exploring": 28}
{"steps": 357180, "mean 100 episode reward": 1739.3, "episodes": 660, "% time spent exploring": 28}
{"steps": 357560, "mean 100 episode reward": 1739.2, "episodes": 661, "% time spent exploring": 28}
{"steps": 357991, "mean 100 episode reward": 1748.0, "episodes": 662, "% time spent exploring": 28}
{"steps": 358167, "mean 100 episode reward": 1742.0, "episodes": 663, "% time spent exploring": 28}
{"steps": 358548, "mean 100 episode reward": 1743.0, "episodes": 664, "% time spent exploring": 28}
{"steps": 358840, "mean 100 episode reward": 1736.5, "episodes": 665, "% time spent exploring": 28}
{"steps": 359006, "mean 100 episode reward": 1732.6, "episodes": 666, "% time spent exploring": 28}
{"steps": 359296, "mean 100 episode reward": 1721.8, "episodes": 667, "% time spent exploring": 28}
{"steps": 359745, "mean 100 episode reward": 1727.5, "episodes": 668, "% time spent exploring": 28}
{"steps": 360025, "mean 100 episode reward": 1722.8, "episodes": 669, "% time spent exploring": 27}
{"steps": 360294, "mean 100 episode reward": 1723.3, "episodes": 670, "% time spent exploring": 27}
{"steps": 360570, "mean 100 episode reward": 1716.2, "episodes": 671, "% time spent exploring": 27}
{"steps": 360990, "mean 100 episode reward": 1725.2, "episodes": 672, "% time spent exploring": 27}
{"steps": 361511, "mean 100 episode reward": 1723.6, "episodes": 673, "% time spent exploring": 27}
{"steps": 361764, "mean 100 episode reward": 1717.4, "episodes": 674, "% time spent exploring": 27}
{"steps": 362187, "mean 100 episode reward": 1714.9, "episodes": 675, "% time spent exploring": 27}
{"steps": 362587, "mean 100 episode reward": 1718.6, "episodes": 676, "% time spent exploring": 27}
{"steps": 362797, "mean 100 episode reward": 1707.0, "episodes": 677, "% time spent exploring": 27}
{"steps": 363031, "mean 100 episode reward": 1704.6, "episodes": 678, "% time spent exploring": 27}
{"steps": 363373, "mean 100 episode reward": 1712.4, "episodes": 679, "% time spent exploring": 27}
{"steps": 363633, "mean 100 episode reward": 1706.8, "episodes": 680, "% time spent exploring": 27}
{"steps": 363735, "mean 100 episode reward": 1697.4, "episodes": 681, "% time spent exploring": 27}
{"steps": 364143, "mean 100 episode reward": 1703.8, "episodes": 682, "% time spent exploring": 27}
{"steps": 364435, "mean 100 episode reward": 1707.6, "episodes": 683, "% time spent exploring": 27}
{"steps": 364737, "mean 100 episode reward": 1707.0, "episodes": 684, "% time spent exploring": 27}
{"steps": 364917, "mean 100 episode reward": 1698.4, "episodes": 685, "% time spent exploring": 27}
{"steps": 365128, "mean 100 episode reward": 1688.1, "episodes": 686, "% time spent exploring": 26}
{"steps": 365457, "mean 100 episode reward": 1685.8, "episodes": 687, "% time spent exploring": 26}
{"steps": 365896, "mean 100 episode reward": 1690.3, "episodes": 688, "% time spent exploring": 26}
{"steps": 366079, "mean 100 episode reward": 1685.6, "episodes": 689, "% time spent exploring": 26}
{"steps": 366400, "mean 100 episode reward": 1693.4, "episodes": 690, "% time spent exploring": 26}
{"steps": 366842, "mean 100 episode reward": 1684.1, "episodes": 691, "% time spent exploring": 26}
{"steps": 367013, "mean 100 episode reward": 1684.6, "episodes": 692, "% time spent exploring": 26}
{"steps": 367147, "mean 100 episode reward": 1677.1, "episodes": 693, "% time spent exploring": 26}
{"steps": 367508, "mean 100 episode reward": 1681.1, "episodes": 694, "% time spent exploring": 26}
{"steps": 367785, "mean 100 episode reward": 1671.6, "episodes": 695, "% time spent exploring": 26}
{"steps": 368052, "mean 100 episode reward": 1673.4, "episodes": 696, "% time spent exploring": 26}
{"steps": 368387, "mean 100 episode reward": 1673.3, "episodes": 697, "% time spent exploring": 26}
{"steps": 368762, "mean 100 episode reward": 1677.2, "episodes": 698, "% time spent exploring": 26}
{"steps": 368908, "mean 100 episode reward": 1672.1, "episodes": 699, "% time spent exploring": 26}
{"steps": 369013, "mean 100 episode reward": 1664.5, "episodes": 700, "% time spent exploring": 26}
{"steps": 369277, "mean 100 episode reward": 1661.9, "episodes": 701, "% time spent exploring": 26}
{"steps": 369383, "mean 100 episode reward": 1644.8, "episodes": 702, "% time spent exploring": 26}
{"steps": 369674, "mean 100 episode reward": 1628.5, "episodes": 703, "% time spent exploring": 26}
{"steps": 369986, "mean 100 episode reward": 1625.7, "episodes": 704, "% time spent exploring": 26}
{"steps": 370270, "mean 100 episode reward": 1624.6, "episodes": 705, "% time spent exploring": 25}
{"steps": 370475, "mean 100 episode reward": 1613.2, "episodes": 706, "% time spent exploring": 25}
{"steps": 370928, "mean 100 episode reward": 1615.7, "episodes": 707, "% time spent exploring": 25}
{"steps": 371502, "mean 100 episode reward": 1631.8, "episodes": 708, "% time spent exploring": 25}
{"steps": 371667, "mean 100 episode reward": 1620.2, "episodes": 709, "% time spent exploring": 25}
{"steps": 372054, "mean 100 episode reward": 1619.2, "episodes": 710, "% time spent exploring": 25}
{"steps": 372228, "mean 100 episode reward": 1611.5, "episodes": 711, "% time spent exploring": 25}
{"steps": 372526, "mean 100 episode reward": 1607.4, "episodes": 712, "% time spent exploring": 25}
{"steps": 372804, "mean 100 episode reward": 1591.4, "episodes": 713, "% time spent exploring": 25}
{"steps": 373040, "mean 100 episode reward": 1586.2, "episodes": 714, "% time spent exploring": 25}
{"steps": 373235, "mean 100 episode reward": 1589.8, "episodes": 715, "% time spent exploring": 25}
{"steps": 373380, "mean 100 episode reward": 1585.7, "episodes": 716, "% time spent exploring": 25}
{"steps": 373535, "mean 100 episode reward": 1589.4, "episodes": 717, "% time spent exploring": 25}
{"steps": 373748, "mean 100 episode reward": 1589.3, "episodes": 718, "% time spent exploring": 25}
{"steps": 374043, "mean 100 episode reward": 1589.8, "episodes": 719, "% time spent exploring": 25}
{"steps": 374318, "mean 100 episode reward": 1588.2, "episodes": 720, "% time spent exploring": 25}
{"steps": 374655, "mean 100 episode reward": 1579.2, "episodes": 721, "% time spent exploring": 25}
{"steps": 375020, "mean 100 episode reward": 1582.6, "episodes": 722, "% time spent exploring": 24}
{"steps": 375292, "mean 100 episode reward": 1582.8, "episodes": 723, "% time spent exploring": 24}
{"steps": 375400, "mean 100 episode reward": 1575.3, "episodes": 724, "% time spent exploring": 24}
{"steps": 375683, "mean 100 episode reward": 1579.5, "episodes": 725, "% time spent exploring": 24}
{"steps": 376019, "mean 100 episode reward": 1571.4, "episodes": 726, "% time spent exploring": 24}
{"steps": 376205, "mean 100 episode reward": 1576.0, "episodes": 727, "% time spent exploring": 24}
{"steps": 376384, "mean 100 episode reward": 1568.0, "episodes": 728, "% time spent exploring": 24}
{"steps": 376685, "mean 100 episode reward": 1562.8, "episodes": 729, "% time spent exploring": 24}
{"steps": 376802, "mean 100 episode reward": 1557.8, "episodes": 730, "% time spent exploring": 24}
{"steps": 377332, "mean 100 episode reward": 1565.4, "episodes": 731, "% time spent exploring": 24}
{"steps": 377641, "mean 100 episode reward": 1570.8, "episodes": 732, "% time spent exploring": 24}
{"steps": 378136, "mean 100 episode reward": 1575.0, "episodes": 733, "% time spent exploring": 24}
{"steps": 378529, "mean 100 episode reward": 1568.5, "episodes": 734, "% time spent exploring": 24}
{"steps": 378847, "mean 100 episode reward": 1568.3, "episodes": 735, "% time spent exploring": 24}
{"steps": 379110, "mean 100 episode reward": 1567.6, "episodes": 736, "% time spent exploring": 24}
{"steps": 379292, "mean 100 episode reward": 1563.7, "episodes": 737, "% time spent exploring": 24}
{"steps": 379638, "mean 100 episode reward": 1569.6, "episodes": 738, "% time spent exploring": 24}
{"steps": 380226, "mean 100 episode reward": 1571.9, "episodes": 739, "% time spent exploring": 23}
{"steps": 380488, "mean 100 episode reward": 1570.8, "episodes": 740, "% time spent exploring": 23}
{"steps": 380737, "mean 100 episode reward": 1567.8, "episodes": 741, "% time spent exploring": 23}
{"steps": 380983, "mean 100 episode reward": 1569.9, "episodes": 742, "% time spent exploring": 23}
{"steps": 381333, "mean 100 episode reward": 1577.4, "episodes": 743, "% time spent exploring": 23}
{"steps": 381683, "mean 100 episode reward": 1577.8, "episodes": 744, "% time spent exploring": 23}
{"steps": 382059, "mean 100 episode reward": 1578.1, "episodes": 745, "% time spent exploring": 23}
{"steps": 382308, "mean 100 episode reward": 1579.3, "episodes": 746, "% time spent exploring": 23}
{"steps": 382656, "mean 100 episode reward": 1576.1, "episodes": 747, "% time spent exploring": 23}
{"steps": 382783, "mean 100 episode reward": 1561.1, "episodes": 748, "% time spent exploring": 23}
{"steps": 383020, "mean 100 episode reward": 1542.3, "episodes": 749, "% time spent exploring": 23}
{"steps": 383185, "mean 100 episode reward": 1538.8, "episodes": 750, "% time spent exploring": 23}
{"steps": 383636, "mean 100 episode reward": 1538.6, "episodes": 751, "% time spent exploring": 23}
{"steps": 383864, "mean 100 episode reward": 1542.0, "episodes": 752, "% time spent exploring": 23}
{"steps": 384151, "mean 100 episode reward": 1547.3, "episodes": 753, "% time spent exploring": 23}
{"steps": 384335, "mean 100 episode reward": 1540.5, "episodes": 754, "% time spent exploring": 23}
{"steps": 384594, "mean 100 episode reward": 1543.8, "episodes": 755, "% time spent exploring": 23}
{"steps": 384754, "mean 100 episode reward": 1532.1, "episodes": 756, "% time spent exploring": 23}
{"steps": 384975, "mean 100 episode reward": 1530.8, "episodes": 757, "% time spent exploring": 23}
{"steps": 385217, "mean 100 episode reward": 1536.2, "episodes": 758, "% time spent exploring": 22}
{"steps": 385430, "mean 100 episode reward": 1534.1, "episodes": 759, "% time spent exploring": 22}
{"steps": 385570, "mean 100 episode reward": 1533.7, "episodes": 760, "% time spent exploring": 22}
{"steps": 386000, "mean 100 episode reward": 1533.2, "episodes": 761, "% time spent exploring": 22}
{"steps": 386420, "mean 100 episode reward": 1529.8, "episodes": 762, "% time spent exploring": 22}
{"steps": 386671, "mean 100 episode reward": 1536.6, "episodes": 763, "% time spent exploring": 22}
{"steps": 386958, "mean 100 episode reward": 1536.1, "episodes": 764, "% time spent exploring": 22}
{"steps": 387352, "mean 100 episode reward": 1535.3, "episodes": 765, "% time spent exploring": 22}
{"steps": 387762, "mean 100 episode reward": 1542.6, "episodes": 766, "% time spent exploring": 22}
{"steps": 387975, "mean 100 episode reward": 1542.6, "episodes": 767, "% time spent exploring": 22}
{"steps": 388179, "mean 100 episode reward": 1532.4, "episodes": 768, "% time spent exploring": 22}
{"steps": 388480, "mean 100 episode reward": 1533.9, "episodes": 769, "% time spent exploring": 22}
{"steps": 388739, "mean 100 episode reward": 1529.9, "episodes": 770, "% time spent exploring": 22}
{"steps": 388986, "mean 100 episode reward": 1532.2, "episodes": 771, "% time spent exploring": 22}
{"steps": 389446, "mean 100 episode reward": 1539.2, "episodes": 772, "% time spent exploring": 22}
{"steps": 389793, "mean 100 episode reward": 1536.1, "episodes": 773, "% time spent exploring": 22}
{"steps": 390213, "mean 100 episode reward": 1545.6, "episodes": 774, "% time spent exploring": 21}
{"steps": 390603, "mean 100 episode reward": 1549.1, "episodes": 775, "% time spent exploring": 21}
{"steps": 390791, "mean 100 episode reward": 1541.2, "episodes": 776, "% time spent exploring": 21}
{"steps": 391014, "mean 100 episode reward": 1541.2, "episodes": 777, "% time spent exploring": 21}
{"steps": 391394, "mean 100 episode reward": 1546.8, "episodes": 778, "% time spent exploring": 21}
{"steps": 391496, "mean 100 episode reward": 1535.4, "episodes": 779, "% time spent exploring": 21}
{"steps": 391854, "mean 100 episode reward": 1545.3, "episodes": 780, "% time spent exploring": 21}
{"steps": 392371, "mean 100 episode reward": 1561.9, "episodes": 781, "% time spent exploring": 21}
{"steps": 392708, "mean 100 episode reward": 1556.8, "episodes": 782, "% time spent exploring": 21}
{"steps": 392998, "mean 100 episode reward": 1560.2, "episodes": 783, "% time spent exploring": 21}
{"steps": 393448, "mean 100 episode reward": 1571.4, "episodes": 784, "% time spent exploring": 21}
{"steps": 393789, "mean 100 episode reward": 1580.7, "episodes": 785, "% time spent exploring": 21}
{"steps": 393907, "mean 100 episode reward": 1576.4, "episodes": 786, "% time spent exploring": 21}
{"steps": 394265, "mean 100 episode reward": 1569.8, "episodes": 787, "% time spent exploring": 21}
{"steps": 394467, "mean 100 episode reward": 1565.5, "episodes": 788, "% time spent exploring": 21}
{"steps": 394934, "mean 100 episode reward": 1569.7, "episodes": 789, "% time spent exploring": 21}
{"steps": 395143, "mean 100 episode reward": 1565.5, "episodes": 790, "% time spent exploring": 20}
{"steps": 395482, "mean 100 episode reward": 1568.8, "episodes": 791, "% time spent exploring": 20}
{"steps": 395757, "mean 100 episode reward": 1572.2, "episodes": 792, "% time spent exploring": 20}
{"steps": 396406, "mean 100 episode reward": 1585.9, "episodes": 793, "% time spent exploring": 20}
{"steps": 396505, "mean 100 episode reward": 1572.6, "episodes": 794, "% time spent exploring": 20}
{"steps": 396735, "mean 100 episode reward": 1561.2, "episodes": 795, "% time spent exploring": 20}
{"steps": 396825, "mean 100 episode reward": 1554.0, "episodes": 796, "% time spent exploring": 20}
{"steps": 397200, "mean 100 episode reward": 1557.4, "episodes": 797, "% time spent exploring": 20}
{"steps": 397290, "mean 100 episode reward": 1544.2, "episodes": 798, "% time spent exploring": 20}
{"steps": 397614, "mean 100 episode reward": 1549.8, "episodes": 799, "% time spent exploring": 20}
{"steps": 397945, "mean 100 episode reward": 1554.4, "episodes": 800, "% time spent exploring": 20}
{"steps": 398981, "mean 100 episode reward": 1564.6, "episodes": 801, "% time spent exploring": 20}
{"steps": 399363, "mean 100 episode reward": 1575.5, "episodes": 802, "% time spent exploring": 20}
{"steps": 400529, "mean 100 episode reward": 1577.7, "episodes": 803, "% time spent exploring": 19}
{"steps": 400800, "mean 100 episode reward": 1572.4, "episodes": 804, "% time spent exploring": 19}
{"steps": 401034, "mean 100 episode reward": 1567.4, "episodes": 805, "% time spent exploring": 19}
{"steps": 401263, "mean 100 episode reward": 1562.3, "episodes": 806, "% time spent exploring": 19}
{"steps": 401513, "mean 100 episode reward": 1559.1, "episodes": 807, "% time spent exploring": 19}
{"steps": 402062, "mean 100 episode reward": 1538.7, "episodes": 808, "% time spent exploring": 19}
{"steps": 402966, "mean 100 episode reward": 1552.2, "episodes": 809, "% time spent exploring": 19}
{"steps": 403062, "mean 100 episode reward": 1539.8, "episodes": 810, "% time spent exploring": 19}
{"steps": 403191, "mean 100 episode reward": 1536.0, "episodes": 811, "% time spent exploring": 19}
{"steps": 403295, "mean 100 episode reward": 1527.9, "episodes": 812, "% time spent exploring": 19}
{"steps": 403616, "mean 100 episode reward": 1528.1, "episodes": 813, "% time spent exploring": 19}
{"steps": 404099, "mean 100 episode reward": 1545.4, "episodes": 814, "% time spent exploring": 19}
{"steps": 404194, "mean 100 episode reward": 1536.9, "episodes": 815, "% time spent exploring": 19}
{"steps": 404617, "mean 100 episode reward": 1544.6, "episodes": 816, "% time spent exploring": 19}
{"steps": 404831, "mean 100 episode reward": 1544.3, "episodes": 817, "% time spent exploring": 19}
{"steps": 405359, "mean 100 episode reward": 1555.1, "episodes": 818, "% time spent exploring": 18}
{"steps": 405622, "mean 100 episode reward": 1550.4, "episodes": 819, "% time spent exploring": 18}
{"steps": 405725, "mean 100 episode reward": 1541.7, "episodes": 820, "% time spent exploring": 18}
{"steps": 405963, "mean 100 episode reward": 1533.4, "episodes": 821, "% time spent exploring": 18}
{"steps": 406168, "mean 100 episode reward": 1533.6, "episodes": 822, "% time spent exploring": 18}
{"steps": 406495, "mean 100 episode reward": 1538.1, "episodes": 823, "% time spent exploring": 18}
{"steps": 406788, "mean 100 episode reward": 1547.2, "episodes": 824, "% time spent exploring": 18}
{"steps": 407060, "mean 100 episode reward": 1539.0, "episodes": 825, "% time spent exploring": 18}
{"steps": 407189, "mean 100 episode reward": 1534.6, "episodes": 826, "% time spent exploring": 18}
{"steps": 407433, "mean 100 episode reward": 1533.6, "episodes": 827, "% time spent exploring": 18}
{"steps": 407530, "mean 100 episode reward": 1529.8, "episodes": 828, "% time spent exploring": 18}
{"steps": 407868, "mean 100 episode reward": 1537.8, "episodes": 829, "% time spent exploring": 18}
{"steps": 408100, "mean 100 episode reward": 1546.1, "episodes": 830, "% time spent exploring": 18}
{"steps": 408327, "mean 100 episode reward": 1537.1, "episodes": 831, "% time spent exploring": 18}
{"steps": 408742, "mean 100 episode reward": 1537.8, "episodes": 832, "% time spent exploring": 18}
{"steps": 409356, "mean 100 episode reward": 1544.3, "episodes": 833, "% time spent exploring": 18}
{"steps": 409663, "mean 100 episode reward": 1541.4, "episodes": 834, "% time spent exploring": 18}
{"steps": 409798, "mean 100 episode reward": 1537.6, "episodes": 835, "% time spent exploring": 18}
{"steps": 410001, "mean 100 episode reward": 1536.6, "episodes": 836, "% time spent exploring": 17}
{"steps": 410364, "mean 100 episode reward": 1551.1, "episodes": 837, "% time spent exploring": 17}
{"steps": 410725, "mean 100 episode reward": 1549.1, "episodes": 838, "% time spent exploring": 17}
{"steps": 411013, "mean 100 episode reward": 1533.8, "episodes": 839, "% time spent exploring": 17}
{"steps": 411429, "mean 100 episode reward": 1542.1, "episodes": 840, "% time spent exploring": 17}
{"steps": 411983, "mean 100 episode reward": 1554.6, "episodes": 841, "% time spent exploring": 17}
{"steps": 412277, "mean 100 episode reward": 1553.1, "episodes": 842, "% time spent exploring": 17}
{"steps": 412479, "mean 100 episode reward": 1543.1, "episodes": 843, "% time spent exploring": 17}
{"steps": 412925, "mean 100 episode reward": 1545.5, "episodes": 844, "% time spent exploring": 17}
{"steps": 413665, "mean 100 episode reward": 1551.4, "episodes": 845, "% time spent exploring": 17}
{"steps": 413766, "mean 100 episode reward": 1542.7, "episodes": 846, "% time spent exploring": 17}
{"steps": 414614, "mean 100 episode reward": 1557.7, "episodes": 847, "% time spent exploring": 17}
{"steps": 415350, "mean 100 episode reward": 1576.6, "episodes": 848, "% time spent exploring": 16}
{"steps": 415453, "mean 100 episode reward": 1573.0, "episodes": 849, "% time spent exploring": 16}
{"steps": 415901, "mean 100 episode reward": 1576.2, "episodes": 850, "% time spent exploring": 16}
{"steps": 416106, "mean 100 episode reward": 1564.6, "episodes": 851, "% time spent exploring": 16}
{"steps": 416378, "mean 100 episode reward": 1567.3, "episodes": 852, "% time spent exploring": 16}
{"steps": 417268, "mean 100 episode reward": 1570.7, "episodes": 853, "% time spent exploring": 16}
{"steps": 417655, "mean 100 episode reward": 1570.7, "episodes": 854, "% time spent exploring": 16}
{"steps": 418008, "mean 100 episode reward": 1569.6, "episodes": 855, "% time spent exploring": 16}
{"steps": 418148, "mean 100 episode reward": 1570.0, "episodes": 856, "% time spent exploring": 16}
{"steps": 418505, "mean 100 episode reward": 1568.5, "episodes": 857, "% time spent exploring": 16}
{"steps": 419133, "mean 100 episode reward": 1579.1, "episodes": 858, "% time spent exploring": 16}
{"steps": 419385, "mean 100 episode reward": 1581.5, "episodes": 859, "% time spent exploring": 16}
{"steps": 419744, "mean 100 episode reward": 1584.9, "episodes": 860, "% time spent exploring": 16}
{"steps": 420261, "mean 100 episode reward": 1596.4, "episodes": 861, "% time spent exploring": 15}
{"steps": 420357, "mean 100 episode reward": 1587.4, "episodes": 862, "% time spent exploring": 15}
{"steps": 420781, "mean 100 episode reward": 1588.4, "episodes": 863, "% time spent exploring": 15}
{"steps": 420872, "mean 100 episode reward": 1577.0, "episodes": 864, "% time spent exploring": 15}
{"steps": 421028, "mean 100 episode reward": 1573.4, "episodes": 865, "% time spent exploring": 15}
{"steps": 421303, "mean 100 episode reward": 1576.2, "episodes": 866, "% time spent exploring": 15}
{"steps": 421525, "mean 100 episode reward": 1574.3, "episodes": 867, "% time spent exploring": 15}
{"steps": 421701, "mean 100 episode reward": 1574.8, "episodes": 868, "% time spent exploring": 15}
{"steps": 422250, "mean 100 episode reward": 1574.5, "episodes": 869, "% time spent exploring": 15}
{"steps": 422555, "mean 100 episode reward": 1580.3, "episodes": 870, "% time spent exploring": 15}
{"steps": 422764, "mean 100 episode reward": 1580.1, "episodes": 871, "% time spent exploring": 15}
{"steps": 423399, "mean 100 episode reward": 1575.0, "episodes": 872, "% time spent exploring": 15}
{"steps": 423632, "mean 100 episode reward": 1570.9, "episodes": 873, "% time spent exploring": 15}
{"steps": 423761, "mean 100 episode reward": 1554.2, "episodes": 874, "% time spent exploring": 15}
{"steps": 424184, "mean 100 episode reward": 1559.9, "episodes": 875, "% time spent exploring": 15}
{"steps": 424463, "mean 100 episode reward": 1566.5, "episodes": 876, "% time spent exploring": 15}
{"steps": 424858, "mean 100 episode reward": 1573.1, "episodes": 877, "% time spent exploring": 15}
{"steps": 425117, "mean 100 episode reward": 1569.0, "episodes": 878, "% time spent exploring": 14}
{"steps": 425251, "mean 100 episode reward": 1573.0, "episodes": 879, "% time spent exploring": 14}
{"steps": 425532, "mean 100 episode reward": 1560.9, "episodes": 880, "% time spent exploring": 14}
{"steps": 425786, "mean 100 episode reward": 1548.8, "episodes": 881, "% time spent exploring": 14}
{"steps": 426524, "mean 100 episode reward": 1560.1, "episodes": 882, "% time spent exploring": 14}
{"steps": 426765, "mean 100 episode reward": 1554.3, "episodes": 883, "% time spent exploring": 14}
{"steps": 426898, "mean 100 episode reward": 1537.5, "episodes": 884, "% time spent exploring": 14}
{"steps": 427275, "mean 100 episode reward": 1532.7, "episodes": 885, "% time spent exploring": 14}
{"steps": 427428, "mean 100 episode reward": 1536.9, "episodes": 886, "% time spent exploring": 14}
{"steps": 427530, "mean 100 episode reward": 1529.1, "episodes": 887, "% time spent exploring": 14}
{"steps": 427835, "mean 100 episode reward": 1530.4, "episodes": 888, "% time spent exploring": 14}
{"steps": 427954, "mean 100 episode reward": 1522.6, "episodes": 889, "% time spent exploring": 14}
{"steps": 428206, "mean 100 episode reward": 1519.1, "episodes": 890, "% time spent exploring": 14}
{"steps": 428626, "mean 100 episode reward": 1517.4, "episodes": 891, "% time spent exploring": 14}
{"steps": 428879, "mean 100 episode reward": 1517.9, "episodes": 892, "% time spent exploring": 14}
{"steps": 429356, "mean 100 episode reward": 1513.4, "episodes": 893, "% time spent exploring": 14}
{"steps": 429512, "mean 100 episode reward": 1517.1, "episodes": 894, "% time spent exploring": 14}
{"steps": 429866, "mean 100 episode reward": 1529.0, "episodes": 895, "% time spent exploring": 14}
{"steps": 429973, "mean 100 episode reward": 1528.7, "episodes": 896, "% time spent exploring": 14}
{"steps": 430323, "mean 100 episode reward": 1526.0, "episodes": 897, "% time spent exploring": 13}
{"steps": 430457, "mean 100 episode reward": 1529.7, "episodes": 898, "% time spent exploring": 13}
{"steps": 430796, "mean 100 episode reward": 1528.3, "episodes": 899, "% time spent exploring": 13}
{"steps": 430904, "mean 100 episode reward": 1523.7, "episodes": 900, "% time spent exploring": 13}
{"steps": 430995, "mean 100 episode reward": 1505.1, "episodes": 901, "% time spent exploring": 13}
{"steps": 431221, "mean 100 episode reward": 1501.8, "episodes": 902, "% time spent exploring": 13}
{"steps": 431601, "mean 100 episode reward": 1507.3, "episodes": 903, "% time spent exploring": 13}
{"steps": 431698, "mean 100 episode reward": 1501.8, "episodes": 904, "% time spent exploring": 13}
{"steps": 431806, "mean 100 episode reward": 1496.1, "episodes": 905, "% time spent exploring": 13}
{"steps": 432362, "mean 100 episode reward": 1506.1, "episodes": 906, "% time spent exploring": 13}
{"steps": 432834, "mean 100 episode reward": 1508.0, "episodes": 907, "% time spent exploring": 13}
{"steps": 433095, "mean 100 episode reward": 1507.9, "episodes": 908, "% time spent exploring": 13}
{"steps": 433199, "mean 100 episode reward": 1491.0, "episodes": 909, "% time spent exploring": 13}
{"steps": 433493, "mean 100 episode reward": 1500.6, "episodes": 910, "% time spent exploring": 13}
{"steps": 433709, "mean 100 episode reward": 1503.9, "episodes": 911, "% time spent exploring": 13}
{"steps": 433878, "mean 100 episode reward": 1507.9, "episodes": 912, "% time spent exploring": 13}
{"steps": 434112, "mean 100 episode reward": 1507.2, "episodes": 913, "% time spent exploring": 13}
{"steps": 434837, "mean 100 episode reward": 1496.8, "episodes": 914, "% time spent exploring": 13}
{"steps": 435427, "mean 100 episode reward": 1509.1, "episodes": 915, "% time spent exploring": 12}
{"steps": 436075, "mean 100 episode reward": 1511.6, "episodes": 916, "% time spent exploring": 12}
{"steps": 436750, "mean 100 episode reward": 1521.6, "episodes": 917, "% time spent exploring": 12}
{"steps": 436854, "mean 100 episode reward": 1503.0, "episodes": 918, "% time spent exploring": 12}
{"steps": 437232, "mean 100 episode reward": 1507.4, "episodes": 919, "% time spent exploring": 12}
{"steps": 437525, "mean 100 episode reward": 1523.5, "episodes": 920, "% time spent exploring": 12}
{"steps": 437934, "mean 100 episode reward": 1530.9, "episodes": 921, "% time spent exploring": 12}
{"steps": 438257, "mean 100 episode reward": 1533.2, "episodes": 922, "% time spent exploring": 12}
{"steps": 438391, "mean 100 episode reward": 1517.0, "episodes": 923, "% time spent exploring": 12}
{"steps": 438773, "mean 100 episode reward": 1516.0, "episodes": 924, "% time spent exploring": 12}
{"steps": 438908, "mean 100 episode reward": 1516.4, "episodes": 925, "% time spent exploring": 12}
{"steps": 439314, "mean 100 episode reward": 1521.7, "episodes": 926, "% time spent exploring": 12}
{"steps": 439663, "mean 100 episode reward": 1525.9, "episodes": 927, "% time spent exploring": 12}
{"steps": 439930, "mean 100 episode reward": 1533.5, "episodes": 928, "% time spent exploring": 12}
{"steps": 440389, "mean 100 episode reward": 1526.0, "episodes": 929, "% time spent exploring": 11}
{"steps": 440739, "mean 100 episode reward": 1525.0, "episodes": 930, "% time spent exploring": 11}
{"steps": 441153, "mean 100 episode reward": 1528.8, "episodes": 931, "% time spent exploring": 11}
{"steps": 441319, "mean 100 episode reward": 1519.2, "episodes": 932, "% time spent exploring": 11}
{"steps": 441778, "mean 100 episode reward": 1508.3, "episodes": 933, "% time spent exploring": 11}
{"steps": 442215, "mean 100 episode reward": 1508.2, "episodes": 934, "% time spent exploring": 11}
{"steps": 442390, "mean 100 episode reward": 1508.6, "episodes": 935, "% time spent exploring": 11}
{"steps": 442897, "mean 100 episode reward": 1525.1, "episodes": 936, "% time spent exploring": 11}
{"steps": 443187, "mean 100 episode reward": 1518.0, "episodes": 937, "% time spent exploring": 11}
{"steps": 443375, "mean 100 episode reward": 1512.5, "episodes": 938, "% time spent exploring": 11}
{"steps": 443668, "mean 100 episode reward": 1520.9, "episodes": 939, "% time spent exploring": 11}
{"steps": 443949, "mean 100 episode reward": 1516.3, "episodes": 940, "% time spent exploring": 11}
{"steps": 444390, "mean 100 episode reward": 1508.0, "episodes": 941, "% time spent exploring": 11}
{"steps": 444680, "mean 100 episode reward": 1508.7, "episodes": 942, "% time spent exploring": 11}
{"steps": 445294, "mean 100 episode reward": 1518.6, "episodes": 943, "% time spent exploring": 10}
{"steps": 445653, "mean 100 episode reward": 1523.8, "episodes": 944, "% time spent exploring": 10}
{"steps": 445904, "mean 100 episode reward": 1511.2, "episodes": 945, "% time spent exploring": 10}
{"steps": 446221, "mean 100 episode reward": 1525.8, "episodes": 946, "% time spent exploring": 10}
{"steps": 446395, "mean 100 episode reward": 1506.7, "episodes": 947, "% time spent exploring": 10}
{"steps": 446496, "mean 100 episode reward": 1488.6, "episodes": 948, "% time spent exploring": 10}
{"steps": 446692, "mean 100 episode reward": 1495.7, "episodes": 949, "% time spent exploring": 10}
{"steps": 446842, "mean 100 episode reward": 1492.4, "episodes": 950, "% time spent exploring": 10}
{"steps": 447018, "mean 100 episode reward": 1491.6, "episodes": 951, "% time spent exploring": 10}
{"steps": 447284, "mean 100 episode reward": 1487.4, "episodes": 952, "% time spent exploring": 10}
{"steps": 447419, "mean 100 episode reward": 1469.1, "episodes": 953, "% time spent exploring": 10}
{"steps": 447641, "mean 100 episode reward": 1472.2, "episodes": 954, "% time spent exploring": 10}
{"steps": 447806, "mean 100 episode reward": 1466.8, "episodes": 955, "% time spent exploring": 10}
{"steps": 448064, "mean 100 episode reward": 1470.4, "episodes": 956, "% time spent exploring": 10}
{"steps": 448323, "mean 100 episode reward": 1476.5, "episodes": 957, "% time spent exploring": 10}
{"steps": 448617, "mean 100 episode reward": 1471.7, "episodes": 958, "% time spent exploring": 10}
{"steps": 448926, "mean 100 episode reward": 1475.8, "episodes": 959, "% time spent exploring": 10}
{"steps": 449507, "mean 100 episode reward": 1482.3, "episodes": 960, "% time spent exploring": 10}
{"steps": 449608, "mean 100 episode reward": 1463.5, "episodes": 961, "% time spent exploring": 10}
{"steps": 449704, "mean 100 episode reward": 1463.7, "episodes": 962, "% time spent exploring": 10}
{"steps": 449934, "mean 100 episode reward": 1460.2, "episodes": 963, "% time spent exploring": 10}
{"steps": 450417, "mean 100 episode reward": 1473.1, "episodes": 964, "% time spent exploring": 9}
{"steps": 450531, "mean 100 episode reward": 1468.9, "episodes": 965, "% time spent exploring": 9}
{"steps": 450926, "mean 100 episode reward": 1464.8, "episodes": 966, "% time spent exploring": 9}
{"steps": 451457, "mean 100 episode reward": 1467.4, "episodes": 967, "% time spent exploring": 9}
{"steps": 451777, "mean 100 episode reward": 1472.0, "episodes": 968, "% time spent exploring": 9}
{"steps": 451893, "mean 100 episode reward": 1463.1, "episodes": 969, "% time spent exploring": 9}
{"steps": 451997, "mean 100 episode reward": 1453.8, "episodes": 970, "% time spent exploring": 9}
{"steps": 452091, "mean 100 episode reward": 1446.0, "episodes": 971, "% time spent exploring": 9}
{"steps": 452200, "mean 100 episode reward": 1431.2, "episodes": 972, "% time spent exploring": 9}
{"steps": 452290, "mean 100 episode reward": 1427.2, "episodes": 973, "% time spent exploring": 9}
{"steps": 452497, "mean 100 episode reward": 1434.6, "episodes": 974, "% time spent exploring": 9}
{"steps": 452603, "mean 100 episode reward": 1413.8, "episodes": 975, "% time spent exploring": 9}
{"steps": 452943, "mean 100 episode reward": 1411.3, "episodes": 976, "% time spent exploring": 9}
{"steps": 453161, "mean 100 episode reward": 1401.2, "episodes": 977, "% time spent exploring": 9}
{"steps": 453383, "mean 100 episode reward": 1398.9, "episodes": 978, "% time spent exploring": 9}
{"steps": 453659, "mean 100 episode reward": 1402.9, "episodes": 979, "% time spent exploring": 9}
{"steps": 453752, "mean 100 episode reward": 1397.6, "episodes": 980, "% time spent exploring": 9}
{"steps": 453886, "mean 100 episode reward": 1392.8, "episodes": 981, "% time spent exploring": 9}
{"steps": 454161, "mean 100 episode reward": 1380.2, "episodes": 982, "% time spent exploring": 9}
{"steps": 454541, "mean 100 episode reward": 1382.6, "episodes": 983, "% time spent exploring": 9}
{"steps": 454785, "mean 100 episode reward": 1382.7, "episodes": 984, "% time spent exploring": 9}
{"steps": 455123, "mean 100 episode reward": 1383.7, "episodes": 985, "% time spent exploring": 9}
{"steps": 455429, "mean 100 episode reward": 1387.6, "episodes": 986, "% time spent exploring": 9}
{"steps": 455642, "mean 100 episode reward": 1391.2, "episodes": 987, "% time spent exploring": 9}
{"steps": 455936, "mean 100 episode reward": 1387.8, "episodes": 988, "% time spent exploring": 9}
{"steps": 456159, "mean 100 episode reward": 1395.3, "episodes": 989, "% time spent exploring": 9}
{"steps": 456520, "mean 100 episode reward": 1400.2, "episodes": 990, "% time spent exploring": 9}
{"steps": 456684, "mean 100 episode reward": 1394.7, "episodes": 991, "% time spent exploring": 9}
{"steps": 456809, "mean 100 episode reward": 1386.5, "episodes": 992, "% time spent exploring": 9}
{"steps": 457220, "mean 100 episode reward": 1389.4, "episodes": 993, "% time spent exploring": 9}
{"steps": 457730, "mean 100 episode reward": 1394.2, "episodes": 994, "% time spent exploring": 9}
{"steps": 457897, "mean 100 episode reward": 1386.2, "episodes": 995, "% time spent exploring": 9}
{"steps": 458155, "mean 100 episode reward": 1394.3, "episodes": 996, "% time spent exploring": 9}
{"steps": 458479, "mean 100 episode reward": 1397.1, "episodes": 997, "% time spent exploring": 9}
{"steps": 458802, "mean 100 episode reward": 1401.4, "episodes": 998, "% time spent exploring": 9}
{"steps": 459211, "mean 100 episode reward": 1402.3, "episodes": 999, "% time spent exploring": 9}
{"steps": 460108, "mean 100 episode reward": 1418.0, "episodes": 1000, "% time spent exploring": 9}
{"steps": 460366, "mean 100 episode reward": 1424.9, "episodes": 1001, "% time spent exploring": 9}
{"steps": 460766, "mean 100 episode reward": 1425.3, "episodes": 1002, "% time spent exploring": 9}
{"steps": 461479, "mean 100 episode reward": 1427.4, "episodes": 1003, "% time spent exploring": 9}
{"steps": 461766, "mean 100 episode reward": 1432.4, "episodes": 1004, "% time spent exploring": 9}
{"steps": 462137, "mean 100 episode reward": 1439.5, "episodes": 1005, "% time spent exploring": 9}
{"steps": 462359, "mean 100 episode reward": 1434.6, "episodes": 1006, "% time spent exploring": 9}
{"steps": 462894, "mean 100 episode reward": 1436.9, "episodes": 1007, "% time spent exploring": 9}
{"steps": 463151, "mean 100 episode reward": 1441.7, "episodes": 1008, "% time spent exploring": 9}
{"steps": 463459, "mean 100 episode reward": 1452.4, "episodes": 1009, "% time spent exploring": 9}
{"steps": 463559, "mean 100 episode reward": 1442.7, "episodes": 1010, "% time spent exploring": 9}
{"steps": 463795, "mean 100 episode reward": 1443.3, "episodes": 1011, "% time spent exploring": 9}
{"steps": 463935, "mean 100 episode reward": 1443.2, "episodes": 1012, "% time spent exploring": 9}
{"steps": 464022, "mean 100 episode reward": 1435.3, "episodes": 1013, "% time spent exploring": 9}
{"steps": 464374, "mean 100 episode reward": 1425.6, "episodes": 1014, "% time spent exploring": 9}
{"steps": 464538, "mean 100 episode reward": 1416.6, "episodes": 1015, "% time spent exploring": 9}
{"steps": 464626, "mean 100 episode reward": 1402.7, "episodes": 1016, "% time spent exploring": 9}
{"steps": 464730, "mean 100 episode reward": 1389.1, "episodes": 1017, "% time spent exploring": 9}
{"steps": 465107, "mean 100 episode reward": 1396.4, "episodes": 1018, "% time spent exploring": 9}
{"steps": 465200, "mean 100 episode reward": 1388.8, "episodes": 1019, "% time spent exploring": 9}
{"steps": 465415, "mean 100 episode reward": 1376.4, "episodes": 1020, "% time spent exploring": 9}
{"steps": 465764, "mean 100 episode reward": 1369.9, "episodes": 1021, "% time spent exploring": 9}
{"steps": 465928, "mean 100 episode reward": 1363.4, "episodes": 1022, "% time spent exploring": 9}
{"steps": 466182, "mean 100 episode reward": 1375.1, "episodes": 1023, "% time spent exploring": 9}
{"steps": 466601, "mean 100 episode reward": 1382.4, "episodes": 1024, "% time spent exploring": 9}
{"steps": 466988, "mean 100 episode reward": 1390.0, "episodes": 1025, "% time spent exploring": 9}
{"steps": 467169, "mean 100 episode reward": 1384.4, "episodes": 1026, "% time spent exploring": 9}
{"steps": 467300, "mean 100 episode reward": 1372.4, "episodes": 1027, "% time spent exploring": 9}
{"steps": 467901, "mean 100 episode reward": 1383.6, "episodes": 1028, "% time spent exploring": 9}
{"steps": 468208, "mean 100 episode reward": 1388.2, "episodes": 1029, "% time spent exploring": 9}
{"steps": 468449, "mean 100 episode reward": 1385.9, "episodes": 1030, "% time spent exploring": 9}
{"steps": 468571, "mean 100 episode reward": 1377.7, "episodes": 1031, "% time spent exploring": 9}
{"steps": 468962, "mean 100 episode reward": 1384.3, "episodes": 1032, "% time spent exploring": 9}
{"steps": 469338, "mean 100 episode reward": 1393.6, "episodes": 1033, "% time spent exploring": 9}
{"steps": 469535, "mean 100 episode reward": 1394.2, "episodes": 1034, "% time spent exploring": 9}
{"steps": 469924, "mean 100 episode reward": 1400.3, "episodes": 1035, "% time spent exploring": 9}
{"steps": 470215, "mean 100 episode reward": 1388.0, "episodes": 1036, "% time spent exploring": 9}
{"steps": 470496, "mean 100 episode reward": 1384.1, "episodes": 1037, "% time spent exploring": 9}
{"steps": 470615, "mean 100 episode reward": 1380.1, "episodes": 1038, "% time spent exploring": 9}
{"steps": 470822, "mean 100 episode reward": 1372.6, "episodes": 1039, "% time spent exploring": 9}
{"steps": 471086, "mean 100 episode reward": 1368.7, "episodes": 1040, "% time spent exploring": 9}
{"steps": 471293, "mean 100 episode reward": 1367.1, "episodes": 1041, "% time spent exploring": 9}
{"steps": 471461, "mean 100 episode reward": 1360.6, "episodes": 1042, "% time spent exploring": 9}
{"steps": 471743, "mean 100 episode reward": 1356.4, "episodes": 1043, "% time spent exploring": 9}
{"steps": 471844, "mean 100 episode reward": 1343.5, "episodes": 1044, "% time spent exploring": 9}
{"steps": 472388, "mean 100 episode reward": 1361.5, "episodes": 1045, "% time spent exploring": 9}
{"steps": 472483, "mean 100 episode reward": 1346.9, "episodes": 1046, "% time spent exploring": 9}
{"steps": 473008, "mean 100 episode reward": 1349.6, "episodes": 1047, "% time spent exploring": 9}
{"steps": 473219, "mean 100 episode reward": 1355.2, "episodes": 1048, "% time spent exploring": 9}
{"steps": 473630, "mean 100 episode reward": 1353.3, "episodes": 1049, "% time spent exploring": 9}
{"steps": 473964, "mean 100 episode reward": 1361.0, "episodes": 1050, "% time spent exploring": 9}
{"steps": 474049, "mean 100 episode reward": 1357.1, "episodes": 1051, "% time spent exploring": 9}
{"steps": 474215, "mean 100 episode reward": 1353.3, "episodes": 1052, "% time spent exploring": 9}
{"steps": 474456, "mean 100 episode reward": 1361.4, "episodes": 1053, "% time spent exploring": 9}
{"steps": 474707, "mean 100 episode reward": 1356.3, "episodes": 1054, "% time spent exploring": 9}
{"steps": 474939, "mean 100 episode reward": 1360.6, "episodes": 1055, "% time spent exploring": 9}
{"steps": 475025, "mean 100 episode reward": 1353.2, "episodes": 1056, "% time spent exploring": 9}
{"steps": 475741, "mean 100 episode reward": 1365.6, "episodes": 1057, "% time spent exploring": 9}
{"steps": 476024, "mean 100 episode reward": 1361.7, "episodes": 1058, "% time spent exploring": 9}
{"steps": 476230, "mean 100 episode reward": 1357.8, "episodes": 1059, "% time spent exploring": 9}
{"steps": 476688, "mean 100 episode reward": 1353.6, "episodes": 1060, "% time spent exploring": 9}
{"steps": 476977, "mean 100 episode reward": 1362.5, "episodes": 1061, "% time spent exploring": 9}
{"steps": 477426, "mean 100 episode reward": 1370.0, "episodes": 1062, "% time spent exploring": 9}
{"steps": 477839, "mean 100 episode reward": 1374.1, "episodes": 1063, "% time spent exploring": 9}
{"steps": 478222, "mean 100 episode reward": 1372.8, "episodes": 1064, "% time spent exploring": 9}
{"steps": 478650, "mean 100 episode reward": 1389.0, "episodes": 1065, "% time spent exploring": 9}
{"steps": 478770, "mean 100 episode reward": 1379.7, "episodes": 1066, "% time spent exploring": 9}
{"steps": 478987, "mean 100 episode reward": 1375.1, "episodes": 1067, "% time spent exploring": 9}
{"steps": 479154, "mean 100 episode reward": 1370.3, "episodes": 1068, "% time spent exploring": 9}
{"steps": 479262, "mean 100 episode reward": 1370.3, "episodes": 1069, "% time spent exploring": 9}
{"steps": 479660, "mean 100 episode reward": 1381.9, "episodes": 1070, "% time spent exploring": 9}
{"steps": 479756, "mean 100 episode reward": 1381.8, "episodes": 1071, "% time spent exploring": 9}
{"steps": 480076, "mean 100 episode reward": 1399.9, "episodes": 1072, "% time spent exploring": 9}
{"steps": 480401, "mean 100 episode reward": 1414.1, "episodes": 1073, "% time spent exploring": 9}
{"steps": 480750, "mean 100 episode reward": 1420.0, "episodes": 1074, "% time spent exploring": 9}
{"steps": 481266, "mean 100 episode reward": 1431.8, "episodes": 1075, "% time spent exploring": 9}
{"steps": 481566, "mean 100 episode reward": 1433.9, "episodes": 1076, "% time spent exploring": 9}
{"steps": 481953, "mean 100 episode reward": 1441.6, "episodes": 1077, "% time spent exploring": 9}
{"steps": 482387, "mean 100 episode reward": 1451.0, "episodes": 1078, "% time spent exploring": 9}
{"steps": 482508, "mean 100 episode reward": 1442.8, "episodes": 1079, "% time spent exploring": 9}
{"steps": 482631, "mean 100 episode reward": 1442.6, "episodes": 1080, "% time spent exploring": 9}
{"steps": 482948, "mean 100 episode reward": 1454.3, "episodes": 1081, "% time spent exploring": 9}
{"steps": 483222, "mean 100 episode reward": 1449.5, "episodes": 1082, "% time spent exploring": 9}
{"steps": 483326, "mean 100 episode reward": 1441.8, "episodes": 1083, "% time spent exploring": 9}
{"steps": 483845, "mean 100 episode reward": 1453.5, "episodes": 1084, "% time spent exploring": 9}
{"steps": 484303, "mean 100 episode reward": 1456.6, "episodes": 1085, "% time spent exploring": 9}
{"steps": 484478, "mean 100 episode reward": 1456.5, "episodes": 1086, "% time spent exploring": 9}
{"steps": 484824, "mean 100 episode reward": 1468.3, "episodes": 1087, "% time spent exploring": 9}
{"steps": 485356, "mean 100 episode reward": 1470.6, "episodes": 1088, "% time spent exploring": 9}
{"steps": 485681, "mean 100 episode reward": 1475.2, "episodes": 1089, "% time spent exploring": 9}
{"steps": 485888, "mean 100 episode reward": 1473.8, "episodes": 1090, "% time spent exploring": 9}
{"steps": 486149, "mean 100 episode reward": 1477.3, "episodes": 1091, "% time spent exploring": 9}
{"steps": 486332, "mean 100 episode reward": 1485.5, "episodes": 1092, "% time spent exploring": 9}
{"steps": 486661, "mean 100 episode reward": 1479.2, "episodes": 1093, "% time spent exploring": 9}
{"steps": 487016, "mean 100 episode reward": 1483.5, "episodes": 1094, "% time spent exploring": 9}
{"steps": 487245, "mean 100 episode reward": 1488.4, "episodes": 1095, "% time spent exploring": 9}
{"steps": 487536, "mean 100 episode reward": 1489.7, "episodes": 1096, "% time spent exploring": 9}
{"steps": 487679, "mean 100 episode reward": 1481.7, "episodes": 1097, "% time spent exploring": 9}
{"steps": 487976, "mean 100 episode reward": 1484.7, "episodes": 1098, "% time spent exploring": 9}
{"steps": 488311, "mean 100 episode reward": 1488.7, "episodes": 1099, "% time spent exploring": 9}
{"steps": 488427, "mean 100 episode reward": 1476.7, "episodes": 1100, "% time spent exploring": 9}
{"steps": 488579, "mean 100 episode reward": 1477.1, "episodes": 1101, "% time spent exploring": 9}
{"steps": 488968, "mean 100 episode reward": 1481.8, "episodes": 1102, "% time spent exploring": 9}
{"steps": 489483, "mean 100 episode reward": 1479.5, "episodes": 1103, "% time spent exploring": 9}
{"steps": 489823, "mean 100 episode reward": 1490.1, "episodes": 1104, "% time spent exploring": 9}
{"steps": 490139, "mean 100 episode reward": 1500.2, "episodes": 1105, "% time spent exploring": 9}
{"steps": 490433, "mean 100 episode reward": 1508.1, "episodes": 1106, "% time spent exploring": 9}
{"steps": 490776, "mean 100 episode reward": 1510.5, "episodes": 1107, "% time spent exploring": 9}
{"steps": 491127, "mean 100 episode reward": 1514.6, "episodes": 1108, "% time spent exploring": 9}
{"steps": 491414, "mean 100 episode reward": 1519.2, "episodes": 1109, "% time spent exploring": 9}
{"steps": 491678, "mean 100 episode reward": 1522.9, "episodes": 1110, "% time spent exploring": 9}
{"steps": 491860, "mean 100 episode reward": 1526.3, "episodes": 1111, "% time spent exploring": 9}
{"steps": 492174, "mean 100 episode reward": 1537.6, "episodes": 1112, "% time spent exploring": 9}
{"steps": 492482, "mean 100 episode reward": 1547.9, "episodes": 1113, "% time spent exploring": 9}
{"steps": 493070, "mean 100 episode reward": 1557.4, "episodes": 1114, "% time spent exploring": 9}
{"steps": 493589, "mean 100 episode reward": 1567.8, "episodes": 1115, "% time spent exploring": 9}
{"steps": 493934, "mean 100 episode reward": 1576.2, "episodes": 1116, "% time spent exploring": 9}
{"steps": 494039, "mean 100 episode reward": 1576.2, "episodes": 1117, "% time spent exploring": 9}
{"steps": 494263, "mean 100 episode reward": 1574.8, "episodes": 1118, "% time spent exploring": 9}
{"steps": 494482, "mean 100 episode reward": 1582.5, "episodes": 1119, "% time spent exploring": 9}
{"steps": 494760, "mean 100 episode reward": 1588.6, "episodes": 1120, "% time spent exploring": 9}
{"steps": 495008, "mean 100 episode reward": 1598.8, "episodes": 1121, "% time spent exploring": 9}
{"steps": 495115, "mean 100 episode reward": 1595.6, "episodes": 1122, "% time spent exploring": 9}
{"steps": 495210, "mean 100 episode reward": 1584.2, "episodes": 1123, "% time spent exploring": 9}
{"steps": 495642, "mean 100 episode reward": 1577.7, "episodes": 1124, "% time spent exploring": 9}
{"steps": 496109, "mean 100 episode reward": 1575.2, "episodes": 1125, "% time spent exploring": 9}
{"steps": 496664, "mean 100 episode reward": 1587.4, "episodes": 1126, "% time spent exploring": 9}
{"steps": 496830, "mean 100 episode reward": 1591.8, "episodes": 1127, "% time spent exploring": 9}
{"steps": 497085, "mean 100 episode reward": 1585.0, "episodes": 1128, "% time spent exploring": 9}
{"steps": 497255, "mean 100 episode reward": 1576.4, "episodes": 1129, "% time spent exploring": 9}
{"steps": 497546, "mean 100 episode reward": 1575.3, "episodes": 1130, "% time spent exploring": 9}
{"steps": 497769, "mean 100 episode reward": 1578.9, "episodes": 1131, "% time spent exploring": 9}
{"steps": 497927, "mean 100 episode reward": 1572.2, "episodes": 1132, "% time spent exploring": 9}
{"steps": 498518, "mean 100 episode reward": 1575.1, "episodes": 1133, "% time spent exploring": 9}
{"steps": 498616, "mean 100 episode reward": 1567.0, "episodes": 1134, "% time spent exploring": 9}
{"steps": 498862, "mean 100 episode reward": 1564.2, "episodes": 1135, "% time spent exploring": 9}
{"steps": 499123, "mean 100 episode reward": 1560.8, "episodes": 1136, "% time spent exploring": 9}
{"steps": 499397, "mean 100 episode reward": 1562.3, "episodes": 1137, "% time spent exploring": 9}
{"steps": 499547, "mean 100 episode reward": 1562.5, "episodes": 1138, "% time spent exploring": 9}
{"steps": 499648, "mean 100 episode reward": 1554.4, "episodes": 1139, "% time spent exploring": 9}
{"steps": 499874, "mean 100 episode reward": 1554.3, "episodes": 1140, "% time spent exploring": 9}
